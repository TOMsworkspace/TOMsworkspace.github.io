{"meta":{"title":"Tom's develop Blog","subtitle":"Love technology,love life.","description":"keep curiously!","author":"Tom","url":"https://TOMsworkspace.github.io","root":"/"},"pages":[{"title":"Category","date":"2019-11-08T08:22:30.000Z","updated":"2019-11-08T15:17:17.138Z","comments":false,"path":"categories/index.html","permalink":"https://tomsworkspace.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2019-11-08T08:19:57.000Z","updated":"2019-11-08T15:16:18.819Z","comments":false,"path":"tags/index.html","permalink":"https://tomsworkspace.github.io/tags/index.html","excerpt":"","text":""},{"title":"Link","date":"2019-11-08T08:26:24.000Z","updated":"2019-11-08T15:15:06.934Z","comments":true,"path":"link/index.html","permalink":"https://tomsworkspace.github.io/link/index.html","excerpt":"","text":""}],"posts":[{"title":"C语言中输入输出所有格式控制符","slug":"C语言中输入输出所有格式控制符","date":"2020-01-16T09:02:06.000Z","updated":"2020-01-16T10:28:54.417Z","comments":true,"path":"2020/01/16/C语言中输入输出所有格式控制符/","link":"","permalink":"https://tomsworkspace.github.io/2020/01/16/C%E8%AF%AD%E8%A8%80%E4%B8%AD%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%89%80%E6%9C%89%E6%A0%BC%E5%BC%8F%E6%8E%A7%E5%88%B6%E7%AC%A6/","excerpt":"","text":"C语言中输入输出所有格式控制符&emsp;最近在重温C语言，发现C语言的输入输出函数scanf和printf函数在控制输入输出时有许多控制符来控制输入输出数据的格式。于是就打算来整理一下。 参考百度百科词条 &emsp;scanf()是C语言中的一个输入函数。与printf函数一样，都被声明在头文件stdio.h里。它是格式输入函数，即按用户指定的格式从键盘上把数据输入到指定的变量之中。 &emsp;printf命令的作用是格式化输出函数，一般用于向标准输出设备按规定格式输出信息。printf()函数的调用格式为：printf（”&lt;格式化字符串&gt;”, &lt;参量表&gt;）。printf()是C语言标准库函数，在 stdio.h 中定义。输出的字符串除了可以使用字母、数字、空格和一些数字符号以外，还可以使用一些转义字符表示特殊的含义。[1] 函数定义&emsp;int printf(char *format…);&emsp;int scanf(const char * restrict format,…); 函数返回值&emsp;printf 函数的返回值为printf实际控制输出的字符数。&emsp;scanf函数返回成功读入的数据项数，读入数据时遇到了“文件结束”则返回EOF。 格式控制字符串format&emsp;printf的格式控制字符串format组成如下： %[flags][width][.prec][length]type &emsp;即：%[标志][最小宽度][.精度][类型长度]类型控制符&emsp;详解见下文。 用法详解&emsp;通常意义上format的格式如下：[]里的内容表示可选，即可带可不带。 %[flags][width][.prec][length]type &emsp;规定输出数据的格式，具体如下：[3] 类型控制符type&emsp;type的字符用于规定输出数据的类型，含义如下： 字符 对应数据类型 含义 d / i int 接受整数值并将它表示为有符号的十进制整数，i是老式写法 o unsigned int 无符号8进制整数(不输出前缀0） u unsigned int 无符号10进制整数 x / X unsigned int 无符号16进制整数，x对应的是abcdef，X对应的是ABCDEF（不输出前缀0x) f(lf) double 单精度浮点数和双精度浮点数用f(lf 在C99开始加入标准，意思和 f 相同) e / E double 科学计数法表示的数，基数为10，此处”e”的大小写代表在输出时用的”e”的大小写 a /A double 16进制科学计数法表示的数，基数为2,以p表示,以16进制输出，此处”a”的大小写代表在输出时用的”p”的大小写 g / G double 有效位数，如：%.8g表示单精度浮点数保留8位有效数字 c char 字符型。可以把输入的数字按照ASCII码相应转换为对应的字符 s / S char * / wchar_t * 字符串。输出字符串中的字符直至字符串中的空字符（字符串以’\\0’结尾，这个’\\0’即空字符） p void * 以16进制形式输出指针 n int * 到此字符之前为止，一共输出的字符个数，不输出文本 % 无输入 不进行转换，输出字符‘%’（百分号）本身 m 无 打印errno值对应的出错内容,(例: printf(“%m\\n”); ) &emsp;注：%g、%G在小数点位数四位或指数大于等于精度时用%e、%E，否则用%f。 标志flags&emsp;flags规定输出样式，取值和含义如下： 字符 字符名称 说明 - 减号 左对齐，右边填充空格(默认右对齐) + 加号 在数字前增加符号 + 或 - 0 数字零 将输出的前面补上0，直到占满指定列宽为止（不可以搭配使用”-“） 空格 输出值为正时加上空格，为负时加上负号 # 井号 type是o、x、X时，增加前缀0、0x、0X;type是e、E、f、g、G时，一定使用小数点;type是g、G时，尾部的0保留 示例：printf(\"%5d\\n\",1000); //默认右对齐,左边补空格printf(\"%-5d\\n\",1000); //左对齐,右边补空格printf(\"%+d %+d\\n\",1000,-1000); //输出正负号printf(\"% d % d\\n\",1000,-1000);//正号用空格替代，负号输出printf(\"%x %#x\\n\",1000,1000); //输出0xprintf(\"%.0f %#.0f\\n\",1000.0,1000.0)//当小数点后不输出值时依然输出小数点printf(\"%g %#g\\n\",1000.0,1000.0); //保留小数点后后的0printf(\"%05d\\n\",1000); //前面补0 输出最小宽度width&emsp;用于控制显示数值的宽度，取值和含义如下： &emsp;n(n=1,2,3,4,5,6…)： 宽度至少为n位，不够以空格填充。 &esmp;* 格式列表中，下一个参数还是width &emsp;width是一个可选的指定最小值字段宽度的十进制数字字符串。如果转换值字符少于字段宽度，该字段将从左到右按指定的字段宽度填充。如果指定了左边调整选项，字段将在右边填充。如果转换结果宽于字段宽度，将扩展该字段以包含转换后的结果。不会发生截断。然而，小的精度可能导致在右边发生截断。 精度.prec&emsp;用于控制小数点后面的位数，取值和含义如下： &emsp;无按缺省精度显示0&emsp;当type=d,i,o,u,x时，没有影响；&emsp;type=e,E,f时，不显示小数点&emsp;n(n=1,2,3…)&emsp;当type=e,E,f时表示的最大小数位数；&emsp;type=其他，表示显示的最大宽度&emsp;prec是指可选的精度。精度是一个.(点)后跟十进制数字字符串。如果没有给出精度，按 0（零）对待。精度指定： * d、o、i、 u、x 或 X 转换的最少数字显示位数。 * e 和 f 转换的基数字符后的最少数字显示位数。 * g 转换的最大有效数字位数。 * s 转换中字符串的最大打印字节数目。 类型长度length&emsp;类型长度指明待输出数据的长度。因为相同类型可以有不同的长度，比如整型有16bits的short int，32bits的int，也有64bits的long int，浮点型有32bits的单精度float和64bits的双精度double。为了指明同一类型的不同长度，类型长度（length）应运而生，成为格式控制字符串的一部分。 length 描述 h 参数被解释为短整型或无符号短整型（仅适用于整数说明符：i、d、o、u、x 和 X）。 l 参数被解释为长整型或无符号长整型，适用于整数说明符（i、d、o、u、x 和 X）及说明符 c（表示一个宽字符）和 s（表示宽字符字符串）。 L 参数被解释为长双精度型（仅适用于浮点数说明符：e、E、f、g 和 G）。 &emsp;根据不同的 format 字符串，函数可能需要一系列的附加参数，每个参数包含了一个要被插入的值，替换了 format 参数中指定的每个 % 标签。参数的个数应与 % 标签的个数相同。 [4] 转义序列&emsp;这些转义序列在字符串中会被自动转换为相应操作命令。使用的常见转义字符如下： 符号 意义 符号 意义 \\a 铃声(提醒) \\b Backspace \\f 换页 \\n 换行 \\r 回车 \\t 水平制表符 \\v 垂直制表符 \\’ 单引号 \\” 双引号 \\\\ 反斜杠 ? 文本问号 \\ooo(例如\\024) ASCII字符(OCX) \\xhh (例如:\\x20) ASCII字符(HEX) \\xhhhh 宽字符(2字节HEX) &emsp;例如，WCHAR f = L’\\x4e00’ 或 WCHAR b[] = L”The Chinese character for one is \\x4e00”。","categories":[{"name":"C","slug":"C","permalink":"https://tomsworkspace.github.io/categories/C/"}],"tags":[{"name":"printf scanf 输入输出 C语言 格式控制","slug":"printf-scanf-输入输出-C语言-格式控制","permalink":"https://tomsworkspace.github.io/tags/printf-scanf-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA-C%E8%AF%AD%E8%A8%80-%E6%A0%BC%E5%BC%8F%E6%8E%A7%E5%88%B6/"}]},{"title":"使用免费CDN服务加速Github博客","slug":"使用免费CDN服务加速Github博客","date":"2020-01-15T10:58:14.000Z","updated":"2020-01-15T12:47:16.970Z","comments":true,"path":"2020/01/15/使用免费CDN服务加速Github博客/","link":"","permalink":"https://tomsworkspace.github.io/2020/01/15/%E4%BD%BF%E7%94%A8%E5%85%8D%E8%B4%B9CDN%E6%9C%8D%E5%8A%A1%E5%8A%A0%E9%80%9FGithub%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"&emsp;最近发现部署在github上的个人博客网站访问加载的时间越来越久了，本身Github就已经很慢了，这个加载的速度令人难以接受，特别是对于有图片等比较大的文件需要加载的时候。于是开始考虑有没有什么方法能加速一下。 &emsp;最好的方法当然是多花点钱，买个服务器把博客网站部署上去，不过哪有免费的东西用着舒服呢。于是发现了一个叫做CDN的加速方式，可以对资源访问进行加速。其实对于个人站点来说，只要能加速网站上的静态文件，比如图片、js文件、css文件，网站的访问速度就会大大的提升。 CDN加速的原理&emsp;CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。——百度百科 七牛云图床&emsp;七牛云就是一个这样的工具。可以把你需要加速的图片放到上面去。也提供免费的空间供你使用，不过需要注册和实名认证。感觉不是太友好。你也可以直接把你的博客网站搬上去。原理都是一样的。 &emsp;配置方法 jsDelivr&emsp;jsDelivr的宗旨是为开发者提供免费公共 CDN 加速服务。通过使用jsDelivr,不移动你需要加速的内容,可以直接加速Github项目上的资源。这样可以将个人博客的访问速度大大提升。关键是配置简单，而且完全免费。大力推荐。 &emsp;jsDelivr介绍 &emsp;配置方法 https://blog.csdn.net/larpland/article/details/101349605 https://blog.csdn.net/qq_36759224/article/details/86936453 https://www.hojun.cn/2019/01/18/ck4wa261r005jdcvas9gv7evx/ 第一步: 发布你的github仓库&emsp;把你博客里用到的图片放到github仓库里。可以另外建立一个仓库来保存用到的图片，这样方便管理。 &emsp;在仓库界面下，点release发布 &emsp;自定义发布版本号 第二步：在文章中引用你需要的资源&emsp;使用方法：https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径例如： https://cdn.jsdelivr.net/gh/TRHX/CDN-for-- itrhx.com@1.0/images/trhx.png https://cdn.jsdelivr.net/gh/TRHX/CDN-for-itrhx.com@2.0.1/css/style.css https://cdn.jsdelivr.net/gh/moezx/cdn@3.1.3//Sakurasou.mp4 &emsp;注意：版本号不是必需的，是为了区分新旧资源，如果不使用版本号，将会直接引用最新资源，除此之外还可以使用某个范围内的版本，查看所有资源等，具体使用方法如下： // 加载任何Github发布、提交或分支 https://cdn.jsdelivr.net/gh/user/repo@version/file // 加载 jQuery v3.2.1 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/dist/jquery.min.js // 使用版本范围而不是特定版本 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2/dist/jquery.min.js https://cdn.jsdelivr.net/gh/jquery/jquery@3/dist/jquery.min.js // 完全省略该版本以获取最新版本 https://cdn.jsdelivr.net/gh/jquery/jquery/dist/jquery.min.js // 将“.min”添加到任何JS/CSS文件中以获取缩小版本，如果不存在，将为会自动生成 https://cdn.jsdelivr.net/gh/jquery/jquery@3.2.1/src/core.min.js // 在末尾添加 / 以获取资源目录列表 https://cdn.jsdelivr.net/gh/jquery/jquery/","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"免费CDN服务","slug":"免费CDN服务","permalink":"https://tomsworkspace.github.io/tags/%E5%85%8D%E8%B4%B9CDN%E6%9C%8D%E5%8A%A1/"},{"name":"加速个人博客","slug":"加速个人博客","permalink":"https://tomsworkspace.github.io/tags/%E5%8A%A0%E9%80%9F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"CDN","slug":"CDN","permalink":"https://tomsworkspace.github.io/tags/CDN/"},{"name":"github","slug":"github","permalink":"https://tomsworkspace.github.io/tags/github/"},{"name":"jsdelivr","slug":"jsdelivr","permalink":"https://tomsworkspace.github.io/tags/jsdelivr/"}]},{"title":"如何在代码中计算时钟周期数","slug":"如何在代码中计算时钟周期数","date":"2020-01-02T12:33:57.000Z","updated":"2020-01-16T10:30:13.045Z","comments":true,"path":"2020/01/02/如何在代码中计算时钟周期数/","link":"","permalink":"https://tomsworkspace.github.io/2020/01/02/%E5%A6%82%E4%BD%95%E5%9C%A8%E4%BB%A3%E7%A0%81%E4%B8%AD%E8%AE%A1%E7%AE%97%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F%E6%95%B0/","excerpt":"","text":"如何在代码中计算代码执行的时钟周期数&emsp;有的时候，需要在代码中获取代码运行的时钟周期数。那么，怎么获取到某段代码在运行时的时钟周期数呢？ 通过获取程序运行时间&emsp;在代码中直接计算一个程序的时钟周期是不容易的。但是计算一个程序的执行时间却是比较容易的。编程语言和操作系统都提供有相关的封装好的接口，可以很方便地调用来得到程序的运行时间。这方面的参考资料很多，我就不去介绍了。 &emsp;如何获取程序的执行时间? Linux环境 || Windows环境 &emsp;下面来介绍一下怎么通过获取的程序执行时间来得到十周周期数。&emsp;CPU时钟周期：通常为节拍脉冲或T周期，即主频的倒数，它是CPU中最小的时间单位，每个动作至少需要一个时钟周期。而主频又与与具体的时间有关。CPU的主频表示每秒进行的时钟周期数。那么运行时间与时钟周期数有如下的计算方式: &emsp;根据获取的运行时间和CPU的主频可以计算出程序的时钟周期数。 直接计算时钟周期数&emsp;也有直接计算时钟周期数的方法。为了给计时测量提供更高的准确度，很多处理器还包含一个运行在始终周期级别的计时器，它是一个特殊的寄存器，每个时钟周期它都会自动加1。这个周期计数器呢，是一个64位无符号数，直观理解，就是如果你的处理器是1GHz的，那么需要570年，它才会从2的64次方绕回到0，所以你大可不必考虑溢出的问题。但是这种方法是依赖于硬件的。首先，并不是每种处理器都有这样的寄存器的；其次，即使大多数都有，实现机制也不一样，因此，我们无法用统一的，与平台无关的接口来使用它们。于是就要使用汇编来处理。在这里给出一个C语言嵌入汇编的例程。 unsigned long long int begin,end,total=0; static __inline__ unsigned long long rdtsc(void) &#123; unsigned hi, lo; __asm__ __volatile__ (\"rdtsc\" : \"=a\"(lo),\"=d\"(hi)); return ( (unsigned long long)lo)|( ((unsigned long long)hi)&lt;&lt;32 ); &#125; int main()&#123; begin=rdtsc(); //这里调用要测试的函数 end=rdtsc(); total = end – begin; // total即為 cpu clock cycle &#125; 存在的问题对于第一种方法 &emsp;对于先计时再计算时钟周期数，除开计时器本身可能存在的精度问题。另外，时间 = 周期数 / 频率，由于频率可能会变（比如我的笔记本的 CPU 通常半速运行在 800MHz，繁忙的时候全速运行在 1.6GHz），那么测得的时间也就不准确了。计算的时钟周期就不准。 对于第二种方法 原文链接 &emsp;在多核时代，RDTSC 指令的准确度大大削弱了，原因有三： 不能保证同一块主板上每个核的 TSC 是同步的； CPU 的时钟频率可能变化，例如笔记本电脑的节能功能； 乱序执行导致 RDTSC 测得的周期数不准，这个问题从 Pentium Pro 时代就存在。 &emsp;在多核下，这两次执行可能会在两个CPU上发生，而这两个CPU的计数器的初值不一定相同（由于完成上电复位的准确时机不同)，（有办法同步，见如何同步），那么就导致结果包含了这个误差，这个误差可正可负，取决于先执行的那块CPU 的时钟计数器是超前还是落后。 &amp;emsp乱序执行这个问题比较简单，但意义深远。在现代 CPU 的复杂架构下，测量几条或几十条指令的耗时是无意义的，因为观测本身会干扰 CPU 的执行（cache, 流水线, 多发射，乱序, 猜测)。要么我们以更宏观的指标来标示性能；要么用专门的手段来减小对观测结果的影响。 &emsp;当然，无论怎样，都不可能测得一个程序的准确时钟周期数。但是在允许一定误差存在的条件下，这些方法是有效的，根据场景合理的选择需要的方法。","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"计算代码时钟周期数","slug":"计算代码时钟周期数","permalink":"https://tomsworkspace.github.io/tags/%E8%AE%A1%E7%AE%97%E4%BB%A3%E7%A0%81%E6%97%B6%E9%92%9F%E5%91%A8%E6%9C%9F%E6%95%B0/"}]},{"title":"Huffman算法实现文件压缩解压","slug":"Huffman算法实现文件压缩解压","date":"2020-01-02T12:33:11.000Z","updated":"2020-01-16T10:30:31.711Z","comments":true,"path":"2020/01/02/Huffman算法实现文件压缩解压/","link":"","permalink":"https://tomsworkspace.github.io/2020/01/02/Huffman%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9%E8%A7%A3%E5%8E%8B/","excerpt":"","text":"Huffman算法实现文件压缩解压前言&emsp;哈夫曼编码是一种贪心算法和二叉树结合的字符编码方式，具有广泛的应用背景，最直观的是文件压缩。下面讲述如何用哈夫曼编解码实现文件的压缩和解压。 哈夫曼编码的概念&emsp;哈夫曼树又称作最优树，是一种带权路径长度最短的树，而通过哈夫曼树构造出的编码方式称作哈夫曼编码。也就是说哈夫曼编码是一个通过哈夫曼树进行的一种编码，一般情况下，以字符 “0” 与 “1” 表示。编码的实现过程很简单，只要实现哈夫曼树，通过遍历哈夫曼树，这里我们从根节点开始向下遍历，如果下个节点是左孩子，则在字符串后面追加 “0”，如果为其右孩子，则在字符串后追加 “1”。结束条件为当前节点为叶子节点，得到的字符串就是叶子节点对应字符的编码。 哈夫曼编码用于文件压缩的原理&emsp;我们都知道根据人类使用文字对应的每个字符都是有特定的频率的。比如说英文，一般来说字母a或者e的使用频率很高。如果我们能给出现频率最高的字符很短的编码，出现最少的字符最长的编码，而且保证每个编码都不是任意一个编码的前缀码。为什么要保证这样呢？如果任意一个编码都不是其他编码的前缀码，那么只要读到一个对应字符的编码那么它对应的字符只有一个，不会产生歧义，这样能保证根据压缩的编码来解压不会出现错误。如果我们用这样的编码来对一个文件进行压缩，那么出现最多的字符将会有最短的编码，可以节省很多的空间，将一个大的文件压缩成一个比较小的文件。而哈夫曼树就是一个可以用来生成这样一种编码的树，以树的叶子节点代表一个字符，从根节点到叶节点的路径形成一个编码，左子树表示比特1，右子树表示比特0，可以交换。这样每个字符对应一个唯一的编码而且任意一个编码都不是其他编码的前缀码。如果我们要压缩一个文件，需要先统计这个字符文件中每个字符出现的频率，然后根据频率来生成一颗哈夫曼树，使频率最高的字符对应于最短的编码。然后根据生成的编码对文件进行压缩。也就是把每个字符替换成其对应的编码来保存。生成后的压缩文件会比原来的文件小得多。然后有根据压缩的编码来对压缩的文件进行解压缩，也就是压缩的反过程。这样又可以恢复出原本的文件了。起到了文件压缩节省空间，同时还增加了文件的保密性。也可以看成是文件的加密和解密。 哈夫曼树实现及其效率&emsp;根据贪心算法的思想实现，把字符出现频率较多的字符用稍微短一点的编码，而出现频率较少的字符用稍微长一点的编码。哈夫曼树就是按照这种思想实现，下面将举例分析创建哈夫曼树的具体过程。下面表格的每一行分别对应字符及出现频率，根据这些信息就能创建一棵哈夫曼树。 字符 出现频率 编码 总二进制位数 a 500 1 500 b 250 01 500 c 120 001 360 d 60 0001 240 e 30 00001 150 f 20 00000 100 &emsp;如下图，将每个字符看作一个节点，将带有频率的字符全部放到优先队列中，每次从队列中取频率最小的两个节点 a 和 b（这里频率最小的 a 作为左子树），然后新建一个节点R，把节点设置为两个节点的频率之和，然后把这个新节点R作为节点A和B的父亲节点。最后再把R放到优先队列中。重复这个过程，直到队列中只有一个元素，即为哈夫曼树的根节点。 &emsp;由上分析可得，哈夫曼编码的需要的总二进制位数为 500 + 500 + 360 + 240 + 150 + 100 = 1850。上面的例子如果用等长的编码对字符进行压缩，实现起来更简单，6 个字符必须要 3 位二进制位表示，解压缩的时候每次从文本中读取 3 位二进制码就能翻译成对应的字符，如 000，001，010，011，100，101 分别表示 a，b，c，d，e，f。则需要总的二进制位数为 （500 + 250 + 120 + 60 + 30 + 20）* 3 = 2940。对比非常明显哈夫曼编码需要的总二进制位数比等长编码需要的要少很多，这里的压缩率为 1850 / 2940 = 62%。哈夫曼编码的压缩率通常在 20% ~90% 之间。 代码实现","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Huffman编码","slug":"Huffman编码","permalink":"https://tomsworkspace.github.io/tags/Huffman%E7%BC%96%E7%A0%81/"},{"name":"文件解压缩","slug":"文件解压缩","permalink":"https://tomsworkspace.github.io/tags/%E6%96%87%E4%BB%B6%E8%A7%A3%E5%8E%8B%E7%BC%A9/"}]},{"title":"http/https代理服务器的代码实现","slug":"http-https代理服务器的代码实现","date":"2019-12-22T08:57:42.000Z","updated":"2020-01-16T10:35:14.938Z","comments":true,"path":"2019/12/22/http-https代理服务器的代码实现/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/22/http-https%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"http/https代理服务器的代码实现代理服务器工作原理&emsp;代理服务器作为一种既是服务器又是客户机的中间程序，主要用于转发客户系统的网络访问请求。但是，代理服务器不只是简单地向真正的因特网服务器转发请求，它还可以控制用户的行为，对接收到的客户请求进行决策，并根据过滤规则对用户请求进行过滤。 &emsp;通过代理服务器，网络管理员可以实现比用包过滤路由器更严格的安全策略。不同于使用通用的包过滤路由器来管理通过防火墙的因特网服务流向，代理服务器通过在网关上为每项需要的应用安装专用的代码（代理服务）来工作。如果网络管理员没有为某一特殊服务安装代理服务代码，该服务就不会被支持，也不会通过防火墙转发相应的客户请求。并且，这种代理服务器码能被配置成仅支持某项服务的网络管理员认为可以接受的那部分特征，而不支持其他的特征。 代理服务器主要功能&emsp;代理服务器具有许多功能。对于我们个人用户而言，通过代理上网，能让我们访问一些直接访问会比较慢的网站，比如互联网用户访问教育网的网站。对于单位而言，内部使用代理可以预先过滤一些病毒，保障上网的安全，还能有效地进行访问控制、网速限制，上网监控等等。 &emsp;以下介绍代理服务器的基本功能： （1）一个lP地址或Internet帐户供多个用户同时使用 &emsp;在目前情况下，IP地址是Internet中有限的宝贵资源，如果将这些IP地址仅仅用于单个的请求Internet访问的用户，不能不说是一种资源浪费。使用代理服务器可以做到通过一个IP同时向多个用户提供Internet的访问，对于通过电话拨号连通Internet的内部网络，则可以实现利用一条电话线，一个modem和一个Internet帐户，让内部网络上所有用户同时访问Internet，这样就充分利用了IP地址资源。 （2）缓存功能，可以降低费用，提高速度 &emsp;安装时，代理服务器会在硬盘上开出一块磁盘空间作为缓存区，将代理用户从Internet上接收的内容下载一份保存起来，当再有用户访问同样内容时，就直接从缓存区传送给用户，而不再从Internet上寻找。代理服务器的这项功能可以大大地提高访问速度，同时也降低了通信费用，是一项相当重要的功能。 （3）对内部网络用户进行权限和信息流量计费管理 &emsp;通过代理服务器，网管员在提供Internet服务时，可以容易地对内部网络用户进行访问权限和信息流量计费的管理。网管员不但能够做到只允许被授权的局域网用户访问Internet，还能够控制这些用户在哪些时间、使用哪台计算机访问哪些类型的Internet服务。对于已经获准访问的Internet的用户，网管员还能够按照多种方式进行信息流量的计费管理，如：按照个人计费、按照部门所属计算机计费等，为网络管理带来了极大的方便。 （4）对进入内部网络的Internet信息实施监控和过滤 &emsp;为了避免那些与业务无关的信息进入内部网络浪费通信资费，各个机构对允许访问的内容往往有一些相应的规定。通过代理服务器，网管员不但可以采取过滤的方法简便地控制从Internet流入内部网络的信息内容，还能对用户访问Internet的情况进行实时监控和建立监查日志存档备查。 实现功能：服务器端&emsp;（1）在指定端口（例如 9080）接收来自客户的 http/https 请求并且根据其中的 URL 地址访问该地址所指向的 http/https 服务器（原服务器），接收服务器的响应报文，并将响应报文转发给对应的客户进行浏览。&emsp;（2）支持日志功能，可以将用户的访问目标和内容记录到指定的文件。&emsp;（3）网站过滤：允许/不允许重点内容访问某些网站&emsp;（4）多级代理功能，可以指定上级代理服务器实现多级代理 客户端 &emsp;实现设置IE代理的GUI界面 实现步骤(1)客户端界面通过修改注册表实现代理设置（2）代理服务器主线程等待客户端连接。（3）代理服务器接收客户端发送的 TCP 请求报文，建立线程处理并解析 HTTP 头部（method, url, host 等信息）。（4）在建立的线程中建立服务器到目标地址的socket连接。（5）开启两个线程来处理上行和下行的流量，只负责单纯的转发。（6）客户端（即浏览器）收到代理服务器返回的报文，解析并显示。 代码idea java项目","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"http/https代理服务器","slug":"http-https代理服务器","permalink":"https://tomsworkspace.github.io/tags/http-https%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8/"}]},{"title":"通过修改注册表来更改IE代理","slug":"通过修改注册表来更改IE代理","date":"2019-12-22T08:16:39.000Z","updated":"2019-12-22T09:46:38.847Z","comments":true,"path":"2019/12/22/通过修改注册表来更改IE代理/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/22/%E9%80%9A%E8%BF%87%E4%BF%AE%E6%94%B9%E6%B3%A8%E5%86%8C%E8%A1%A8%E6%9D%A5%E6%9B%B4%E6%94%B9IE%E4%BB%A3%E7%90%86/","excerpt":"","text":"通过修改注册表来更改IE浏览器的代理设置一、什么是注册表&emsp;注册表是windows操作系统、硬件设备以及客户应用程序得以正常运行和保存设置的核心“数据库”，也可以说是一个非常巨大的树状分层结构的数据库系统。&emsp;注册表记录了用户安装在计算机上的软件和每个程序的相互关联信息，它包括了计算机的硬件配置，包括自动配置的即插即用的设备和已有的各种设备说明、状态属性以及各种状态信息和数据。利用一个功能强大的注册表数据库来统一集中地管理系统硬件设施、软件配置等信息，从而方便了管理，增强了系统的稳定性。 二、注册表的功能&emsp;注册表是windows操作系统中的一个核心数据库，其中存放着各种参数，直接控制着windows的启动、硬件驱动程序的装载以及一些windows应用程序的运行，从而在整个系统中起着核心作用。这些作用包括了软、硬件的相关配置和状态信息，比如注册表中保存有应用程序和资源管理器外壳的初始条件、首选项和卸载数据等，联网计算机的整个系统的设置和各种许可，文件扩展名与应用程序的关联，硬件部件的描述、状态和属性，性能记录和其他底层的系统状态信息，以及其他数据等。&emsp;具体来说，在启动Windows时，Registry会对照已有硬件配置数据，检测新的硬件信息；系统内核从Registry中选取信息，包括要装入什么设备驱动程序，以及依什么次序装入，内核传送回它自身的信息，例如版权号等；同时设备驱动程序也向Registry传送数据，并从Registry接收装入和配置参数，一个好的设备驱动程序会告诉Registry它在使用什么系统资源，例如硬件中断或DMA通道等，另外，设备驱动程序还要报告所发现的配置数据；为应用程序或硬件的运行提供增加新的配置数据的服务。配合ini文件兼容16位Windows应用程序，当安装—个基于Windows 3.x的应用程序时，应用程序的安装程序Setup像在windows中—样创建它自己的INI文件或在win.ini和system.ini文件中创建入口；同时windows还提供了大量其他接口，允许用户修改系统配置数据，例如控制面板、设置程序等。&emsp;如果注册表受到了破坏，轻则使windows的启动过程出现异常，重则可能会导致整个windows系统的完全瘫痪。因此正确地认识、使用，特别是及时备份以及有问题恢复注册表对windows用户来说就显得非常重要。 如何打开注册表&emsp;打开注册表的命令是： regedit或regedit.exe、regedt32或regedt32.exe &emsp;正常情况下，你可以点击开始菜单当中的运行，然后输入regedit或regedit.exe点击确定就能打开windows操作系统自带的注册表编辑器了，有图慎重提醒，操作注册表有可能造成系统故障，若您是对windows注册表不熟悉、不了解或没有经验的windows操作系统用户建议尽量不要随意操作注册表。 &emsp;如果上述打开注册表的方法不能使用，说明你没有管理员权限，或者注册表被锁定，如果是没有权限，请寻找电脑管理员帮助解决，如果注册表被锁定，请参照下面的方式进行解锁。 注册表解锁常见的方法：&emsp;1：创建一个文本文件，复制以下文字文本内容（注意开头之后第二行一定要是空行并且不可少），选择另存为，文件类型选择所有文件，文件名称为注册表解锁.reg REGEDIT4[HKEY_USERS.DEFAULT\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\system&quot;DisableRegistryTools&quot;=dword:00000000] 保存文件到桌面，双击打开桌面上的注册表解锁.reg如下图，点击确定即可。 &emsp;2：使用第三方工具恢复，比如使用超级兔子或者优化大师这类系统辅助软件，以下以优化大师为例说明：打开优化大师，点击左侧的系统优化，然后选择系统安全优化，点击右侧的更多设置，，取消禁用注册表编辑器项目前面的对勾。 &emsp;3：利用系统策略编辑器在Windows 2000/XP/2003操作系统下在Windows 2000/XP/2003等操作系统当中，我们可以通过单击 开始-运行，输入gpedit.msc之后点击确定或按回车，打开windows操作系统自带的组策略编辑器。然后，依次展开用户配置-管理模板-系统，双击右侧窗口中的阻止访问注册表编辑工具，在弹出的窗口中选择已禁用，确定后再退出组策略编辑器，即可为注册表解锁。 如何修改浏览器的IE设置&emsp;一般来说，可以通过系统系带的图形界面来更改IE的代理服务器设置 &emsp;对于Win10系统，打开设置，选择网络和internet,再选择左下角的代理就可以进行设置。或者再网络图标点击右键打开网络和Internet设置，选择代理进行设置。 &emsp;对于更低版本的Windows系统，在网络图标上点击右键打开网络和Internet设置，在搜索栏里搜索代理，就可以进行代理服务器的设置。 也可以直接在浏览器的设置菜单里实现对代理的修改 可是有的时候，我们就需要运用其他方式对代理进行更改。于是可以选择更改注册表来实现ie代理的更改。有两种方法： 通过自动生成注册表文件，再调用reg.exe命令&emsp;在说明本文之前，首先说明有比较简单的方法，java程序自动生成注册表文件*.reg，格式为： REGEDIT4[HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings]&quot;ProxyEnable&quot;=dword:00000001&quot;ProxyServer&quot;=&quot;localhost:8080&quot;&quot;ProxyOverride&quot;=&quot;&lt;localhost&gt;&quot; 然后调用，Runtime.getRuntime().exec( “reg.exe import “ + filename); 通过调用registry的api修改&emsp;既然目前已经有现成的修改注册表的包jni的registry包，那我们就不费这个事做上面的操作了，registry jar包下载地址，另外发现openorg上也有类似的，但是类名改掉了，感兴趣的同学可以去搜搜。 IE代理服务器对应于注册表中字段：HKEY_CURRENT_USER\\Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings下面的值：ProxyServer，ProxyEnable，ProxyOverrideProxyEnable用来表示是否使用代理，用0,1表示，类型为REG_DWORD，不能为REG_SZProxyServer用来表示代理服务器ip:port，如localhost:8080，类型为REG_SZProxyOverride表示跳过代理的配置，比如跳过本地代理，该值为 原文链接：https://blog.csdn.net/iteye_21060/article/details/82212107 通过bat脚本设置系统代理，然后在java中调用batjava的Runtime.getRuntime().exec(commandStr)可以调用执行cmd指令。通过他来调用运行bat脚本的cmd命令来实现更改。 原文链接：https://blog.csdn.net/baidu_23275675/article/details/84427757 修改注册表带来的一个问题&emsp;通过修改注册表来实现对代理设置的更改不会立即生效，这是注册表本身自带的缺陷。对于这个问题也是有解决办法的：如何使更改注册表立即生效","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"修改注册表","slug":"修改注册表","permalink":"https://tomsworkspace.github.io/tags/%E4%BF%AE%E6%94%B9%E6%B3%A8%E5%86%8C%E8%A1%A8/"},{"name":"更改IE代理","slug":"更改IE代理","permalink":"https://tomsworkspace.github.io/tags/%E6%9B%B4%E6%94%B9IE%E4%BB%A3%E7%90%86/"},{"name":"IE代理设置","slug":"IE代理设置","permalink":"https://tomsworkspace.github.io/tags/IE%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE/"}]},{"title":"修改Windows系统注册表并使其立即生效","slug":"修改Windows系统注册表并使其立即生效","date":"2019-12-22T07:38:06.000Z","updated":"2020-01-15T09:24:35.554Z","comments":true,"path":"2019/12/22/修改Windows系统注册表并使其立即生效/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/22/%E4%BF%AE%E6%94%B9Windows%E7%B3%BB%E7%BB%9F%E6%B3%A8%E5%86%8C%E8%A1%A8%E5%B9%B6%E4%BD%BF%E5%85%B6%E7%AB%8B%E5%8D%B3%E7%94%9F%E6%95%88/","excerpt":"","text":"修改Windows系统注册表并使其立即生效什么是注册表&emsp;注册表是windows操作系统、硬件设备以及客户应用程序得以正常运行和保存设置的核心“数据库”，也可以说是一个非常巨大的树状分层结构的数据库系统。&emsp;注册表记录了用户安装在计算机上的软件和每个程序的相互关联信息，它包括了计算机的硬件配置，包括自动配置的即插即用的设备和已有的各种设备说明、状态属性以及各种状态信息和数据。利用一个功能强大的注册表数据库来统一集中地管理系统硬件设施、软件配置等信息，从而方便了管理，增强了系统的稳定性。 注册表的功能&emsp;注册表是windows操作系统中的一个核心数据库，其中存放着各种参数，直接控制着windows的启动、硬件驱动程序的装载以及一些windows应用程序的运行，从而在整个系统中起着核心作用。这些作用包括了软、硬件的相关配置和状态信息，比如注册表中保存有应用程序和资源管理器外壳的初始条件、首选项和卸载数据等，联网计算机的整个系统的设置和各种许可，文件扩展名与应用程序的关联，硬件部件的描述、状态和属性，性能记录和其他底层的系统状态信息，以及其他数据等。&emsp;具体来说，在启动Windows时，Registry会对照已有硬件配置数据，检测新的硬件信息；系统内核从Registry中选取信息，包括要装入什么设备驱动程序，以及依什么次序装入，内核传送回它自身的信息，例如版权号等；同时设备驱动程序也向Registry传送数据，并从Registry接收装入和配置参数，一个好的设备驱动程序会告诉Registry它在使用什么系统资源，例如硬件中断或DMA通道等，另外，设备驱动程序还要报告所发现的配置数据；为应用程序或硬件的运行提供增加新的配置数据的服务。配合ini文件兼容16位Windows应用程序，当安装—个基于Windows 3.x的应用程序时，应用程序的安装程序Setup像在windows中—样创建它自己的INI文件或在win.ini和system.ini文件中创建入口；同时windows还提供了大量其他接口，允许用户修改系统配置数据，例如控制面板、设置程序等。&emsp;如果注册表受到了破坏，轻则使windows的启动过程出现异常，重则可能会导致整个windows系统的完全瘫痪。因此正确地认识、使用，特别是及时备份以及有问题恢复注册表对windows用户来说就显得非常重要。 如何打开注册表&emsp;打开注册表的命令是： regedit或regedit.exe、regedt32或regedt32.exe &emsp;正常情况下，你可以点击开始菜单当中的运行，然后输入regedit或regedit.exe点击确定就能打开windows操作系统自带的注册表编辑器了，有图慎重提醒，操作注册表有可能造成系统故障，若您是对windows注册表不熟悉、不了解或没有经验的windows操作系统用户建议尽量不要随意操作注册表。 &emsp;如果上述打开注册表的方法不能使用，说明你没有管理员权限，或者注册表被锁定，如果是没有权限，请寻找电脑管理员帮助解决，如果注册表被锁定，请参照下面的方式进行解锁。 注册表解锁常见的方法：&emsp;1：创建一个文本文件，复制以下文字文本内容（注意开头之后第二行一定要是空行并且不可少），选择另存为，文件类型选择所有文件，文件名称为注册表解锁.reg REGEDIT4[HKEY_USERS.DEFAULT\\Software\\Microsoft\\Windows\\CurrentVersion\\Policies\\system&quot;DisableRegistryTools&quot;=dword:00000000] 保存文件到桌面，双击打开桌面上的注册表解锁.reg如下图，点击确定即可。 &emsp;2：使用第三方工具恢复，比如使用超级兔子或者优化大师这类系统辅助软件，以下以优化大师为例说明：打开优化大师，点击左侧的系统优化，然后选择系统安全优化，点击右侧的更多设置，，取消禁用注册表编辑器项目前面的对勾。 &emsp;3：利用系统策略编辑器在Windows 2000/XP/2003操作系统下在Windows 2000/XP/2003等操作系统当中，我们可以通过单击 开始-运行，输入gpedit.msc之后点击确定或按回车，打开windows操作系统自带的组策略编辑器。然后，依次展开用户配置-管理模板-系统，双击右侧窗口中的阻止访问注册表编辑工具，在弹出的窗口中选择已禁用，确定后再退出组策略编辑器，即可为注册表解锁。 修改注册表后立即生效的方法&emsp;有时候需要对修改后的注册表使他立即生效。 &emsp;要让修改后的注册表生效通常有三种方法： 刷新。也就是说修改注册表后可以立即生效（一些修改是可以的）。几个修改注册表后立即生效的刷新方法 重启explorer进程。这也是通常替代重启的最简单的方法（适用绝大多数）。手动&amp;emsp修改注册表后，一般需要重启才能生效，当然你也可以做到不重启就生效，同时按下Ctrl+Shift+Esc组合键，在弹出的Windows任务列表中，选择Explore，单击“结束进程”按钮，接着在弹出的警告对话框中单击“是”，然后单击“Windows任务管理器”的“文件→新任务（运行）”，在弹出的“创建新任务”的“打开”文本框中输入：explorer，回车后“资源管理器”重新载入，同时修改的注册表也会一并生效。 bat批处理脚本&emsp;在记事本里，输入以下内容，并保存为Reflash.BAT文件即可！ @echo offecho explorer.exe已关闭！taskkill /im explorer.exe /fecho 正在开启explorer.exestart &quot;&quot; &quot;C:\\WINDOWS\\explorer.exe&quot;echo explorer.exe已开启！ping -n 4 127.1&gt;nulexit 语法说明：@echo off 是不显示执行命令echo 后面接显示的文字调用taskkill结束进程 /im指定要终止的进程，后面接进程名 /f强行终止进程echo 后面接显示的文字start 启动，后面接可执行程序及其位置echo 后面接显示的文字ping 是测试连接的命令 -n 4是只发送一次命令，并且延迟3秒 127.1是本机保留IP地址 &gt;nul是把命令重定向到空exit 退出 &emsp;这个BAT文件，会在双击后，自动结束“explorer进程”，然后又会新建explorer进程来使得修改后的注册表生效。用这个简单的方法基本上可以解决日常注册表的修改！ 3、重启。有一些修改是必须要重启计算机的，没有什么其他捷径可言（适用全部)如果以上的方法都没有生效，那么重启是一定可以让你更改的注册表生效的。","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"-修改注册表立即生效","slug":"修改注册表立即生效","permalink":"https://tomsworkspace.github.io/tags/%E4%BF%AE%E6%94%B9%E6%B3%A8%E5%86%8C%E8%A1%A8%E7%AB%8B%E5%8D%B3%E7%94%9F%E6%95%88/"}]},{"title":"Mips-register","slug":"Mips-register","date":"2019-12-07T06:54:25.000Z","updated":"2020-01-15T09:39:28.361Z","comments":true,"path":"2019/12/07/Mips-register/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/07/Mips-register/","excerpt":"","text":"一. 简介&emsp;MIPS有32个通用寄存器（$0-$31），各寄存器的功能及汇编程序中使用约定如下： &emsp;下表描述32个通用寄存器的别名和用途 REGISTER NAME USAGE $0 $zero 常量0(constant value 0) $1 $at 保留给汇编器(Reserved for assembler) $2-$3 $v0-$v1 函数调用返回值(values for results and expression evaluation) $4-$7 $a0-$a3 函数调用参数(arguments) $8-$15 $t0-$t7 暂时的(或随便用的) $16-$23 $s0-$s7 保存的(或如果用，需要SAVE/RESTORE的)(saved) $24-$25 $t8-$t9 暂时的(或随便用的) $28 $gp 全局指针(Global Pointer) $29 $sp 堆栈指针(Stack Pointer) $30 $fp 帧指针(Frame Pointer) $31 $ra 返回地址(return address) 二. 详细说明&emsp;$0: 即$zero,该寄存器总是返回零，为0这个有用常数提供了一个简洁的编码形式。 move $t0,$t1 实际为 add $t0,$0,$t1 使用伪指令可以简化任务，汇编程序提供了比硬件更丰富的指令集。 &emsp;$1: 即$at，该寄存器为汇编保留，由于I型指令的立即数字段只有16位，在加载大常数时，编译器或汇编程序需要把大常数拆开，然后重新组合到寄存器里。比如加载一个32位立即数需要 lui（装入高位立即数）和addi两条指令。像MIPS程序拆散和重装大常数由汇编程序来完成，汇编程序必需一个临时寄存器来重组大常数，这也是为汇编 保留$at的原因之一。 &emsp;$2..$3: ($v0-$v1)用于子程序的非浮点结果或返回值，对于子程序如何传递参数及如何返回，MIPS范围有一套约定，堆栈中少数几个位置处的内容装入CPU寄存器，其相应内存位置保留未做定义，当这两个寄存器不够存放返回值时，编译器通过内存来完成。 &emsp;$4..$7: ($a0-$a3)用来传递前四个参数给子程序，不够的用堆栈。a0-a3和v0-v1以及ra一起来支持子程序／过程调用，分别用以传递参数，返回结果和存放返回地址。当需要使用更多的寄存器时，就需要堆栈（stack)了,MIPS编译器总是为参数在堆栈中留有空间以防有参数需要存储。 &emsp;$8..$15: ($t0-$t7)临时寄存器，子程序可以使用它们而不用保留。 &emsp;$16..$23: ($s0-$s7)保存寄存器，在过程调用过程中需要保留（被调用者保存和恢复，还包括$fp和$ra），MIPS提供了临时寄存器和保存寄存器，这样就减少了寄存器溢出（spilling,即将不常用的变量放到存储器的过程),编译器在编译一个叶（leaf)过程（不调用其它过程的过程）的时候，总是在临时寄存器分配完了才使用需要保存的寄存器。 &emsp;$24..$25: ($t8-$t9)同($t0-$t7) &emsp;$26..$27: ($k0,$k1)为操作系统／异常处理保留，至少要预留一个。 异常（或中断）是一种不需要在程序中显示调用的过程。MIPS有个叫异常程序计数器（exception program counter,EPC)的寄存器，属于CP0寄存器，用于保存造成异常的那条指令的地址。查看控制寄存器的唯一方法是把它复制到通用寄存器里，指令mfc0(move from system control)可以将EPC中的地址复制到某个通用寄存器中，通过跳转语句（jr)，程序可以返回到造成异常的那条指令处继续执行。MIPS程序员都必须保留两个寄存器$k0和$k1，供操作系统使用。 &emsp;发生异常时，这两个寄存器的值不会被恢复，编译器也不使用k0和k1,异常处理函数可以将返回地址放到这两个中的任何一个，然后使用jr跳转到造成异常的指令处继续执行。 &emsp;$28: ($gp)为了简化静态数据的访问，MIPS软件保留了一个寄存器：全局指针gp(global pointer,$gp)，全局指针只想静态数据区中的运行时决定的地址，在存取位于gp值上下32KB范围内的数据时，只需要一条以gp为基指针的指令即可。在编译时，数据须在以gp为基指针的64KB范围内。 &emsp;$29: ($sp)MIPS硬件并不直接支持堆栈，你可以把它用于别的目的，但为了使用别人的程序或让别人使用你的程序， 还是要遵守这个约定的，但这和硬件没有关系。 &emsp;$30: ($fp)GNU MIPS C编译器使用了帧指针(frame pointer),而SGI的C编译器没有使用，而把这个寄存器当作保存寄存器使用（$s8),这节省了调用和返回开销，但增加了代码生成的复杂性。 &emsp;$31: ($ra)存放返回地址，MIPS有个jal(jump-and-link,跳转并 链接)指令，在跳转到某个地址时，把下一条指令的地址放到$ra中。用于支持子程序，例如调用程序把参数放到$a0~$a3,然后jal X跳到X过程，被调过程完成后把结果放到$v0,$v1,然后使用jr $ra返回。","categories":[{"name":"Computer Architecture","slug":"Computer-Architecture","permalink":"https://tomsworkspace.github.io/categories/Computer-Architecture/"}],"tags":[{"name":"MIPs","slug":"MIPs","permalink":"https://tomsworkspace.github.io/tags/MIPs/"},{"name":"Mips寄存器","slug":"Mips寄存器","permalink":"https://tomsworkspace.github.io/tags/Mips%E5%AF%84%E5%AD%98%E5%99%A8/"}]},{"title":"GPU的应用与发展","slug":"GPU的应用与发展","date":"2019-12-07T06:54:05.000Z","updated":"2020-01-15T09:31:59.221Z","comments":true,"path":"2019/12/07/GPU的应用与发展/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/07/GPU%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E5%8F%91%E5%B1%95/","excerpt":"","text":"1. GPU的起源&emsp;&emsp;作为计算机中主要计算单元的中央处理器CPU（Central Process unit）经过了50多年的发展，已经具有很高的运算速度，CPU受工艺和功耗的约束时钟频率已经到达了极限，很难再有提高[1]。但随着图形图像处理技术的进一步发展，对于运算速度有了更高的要求，于是用于实现图形加速的GPU就随之产生了。图形处理器GPU（Graphic Processing Unit）的概念，最先由NVIDIA公司在1999年发布它的GeForce 256图形处理芯片时提出。一块标准的GPU芯片一般主要包括如下的部件：2D单元、3D单元、视频处理单元、FSAA(Full Scene Anti-aliasing全景抗锯齿)单元和显存管理单元[2]。 2. GPU与CPU的对比&emsp;&emsp;作为从CPU之上发展起来的GPU，它们之间存在着差异。 &emsp;&emsp;首先是两者架构的不同。CPU一般由逻辑运算单元ALU，控制单元和存储单元组成。CPU有70%的晶体管用来构建Cache和一部分控制单元。CPU虽然有多核，但总数没有超过两位数，每个核都有足够大的缓存。CPU有足够多的数字和逻辑运算单元，并辅助有很多加速分支判断甚至更复杂的逻辑判断的硬件。所以CPU拥有超强的逻辑能力。GPU包括大量的运算单元，数字逻辑运算单元也少而简单。GPU的核数远超CPU，被称为众核，但每个核拥有的缓存大小相对小。于是GPU拥有超高的运算速度[3]。由于拥有多核，GPU的功耗远远超过CPU。 &emsp;&emsp;其次是应用场景。由于GPU的设计架构，GPU对于数据量大，类型不复杂，具有类似性，计算量大但是逻辑性不强的平行数据具有很强的并行运算能力[4]。而CPU是设计用来处理串行任务的处理、加工、运算以及系统核心控制等工作，CPU的架构是为高效率处理数据相关性不大的计算类、复杂繁琐的非计算类等工作而设计的。GPU相对于CPU拥有高带宽的独立显存、高浮点运算性能、几何计算能力强、适合处理并行计算任务的优势[4]。 3. GPU的应用&emsp;&emsp;GPU最早的设计用途是用于作为CPU的辅助计算部件，用于加速图形图像计算，基本上是为了进行图形的消隐，纹理映射，图形的坐标位置变换、光照计算等。基于Intel提出Larrabee架构,NVIDIA提出的CUDA（Compute Unified Device Architecture统一计算设备架构）等[3]。使GPU变为一种可编程的显示计算通用架构芯片有了更多的用途。 &emsp;&emsp;现代的GPU应用于高性能计算[5]，基于GPU的异构计算系统应用于超级计算机的研发。如我国的自主研发的千亿万级超级计算机“天河一号”使用的便是GPU+x64 CPU的基础架构。天河一号采用14336个英特尔六核处理器Xeon X5670 2.93GHz和2048颗拥有我国自主知识产权的x64八核处理器飞腾FT-100作为超算的主控处理器和调度节点。系统的协处理器采用了英伟达Tesla M2050 GPU。超级计算机“神威·太湖之光”也是基于GPU+CPU架构完成的[6]。&emsp;&emsp;现代GPU也被用于人工智能与机器学习领域。人工智能和机器学习两者都是大规模并行问题，而这正是GPU所擅长的。意大利能源公司 Eni和美国的Stone Ridge科技使用3200个NVIDIA Tesla GPU和Stone Ridge的ECHELON软件进行基于GPU 的油矿仿真,在大约 15.5 小时内就能处理了10万个油矿模型,每一个模型平均在28分钟内就能仿真了油矿15年的生产量。如果使用传统的硬件和软件,完成这项任务需要10天的时间[7]。 4. GPU的发展历程&emsp;&emsp;GPU技术发展的主要主要引导者是NVIDIA。NVIDIA占有着最大的市场份额[8]。到目前为止，NVIDIA公司一共正式发布了六款GPU 核心架构，分别是2008 年推出的Tesla 架构（首次发布了 CUDA 通用并行计算开发架构）、2010 年推出的Fermi架构（首次在GPU 中增加了FP64 双精度浮点运算处理核）、2012 年推出的Kepler架构（首次在GPU中引入了动态并行计算技术）、2014年推出的Maxwell架构（低 功耗优化及支持微软的DX12图形加速接口）、2016年推出的Pascal架构（优化统一内存寻址unified memory机制，首次引入3D内存及NVLink 高速互联总线）、2017年5月推出的Volta架构（首次引入Tensor（张量）运算单元）[9]。 &emsp;&emsp;GPU芯片如今主要的应用于高性能计算领域，基于GPU的异构计算系统应用于超级计算机的研发。应用于人工智能，机器学习技术，甚至还出现了专用于深度学习的GPU芯片[10]。未来的GPU芯片将朝着更小的体积，更快的运算速度，更低的成本，更广的应用范围，更高的集成度发展。 &emsp;&emsp;随着可编程的显示计算通用架构芯片的成熟，它将逐步取代GPU的地位，显卡则会慢慢被集成取代，作为独立硬件生存的空间会越来越小。正如英特尔公司高级副总裁兼数字企业事业部总经理帕特·基辛格在IDF 峰会上的讲话。“可编程的显示计算通用架构芯片是一场革命，它将颠覆持续了几十年的显卡产业，可编程的显示计算通用架构芯片虽然不会马上替代显卡，但是在三四年之后，随着我们相关技术、产品的成熟上市，显卡产业将消亡。”[2] 参考文献[1]李红辉,刘冬冬,杨芳南.CPU+GPU异构并行计算技术研究[J].信息系统工程,2018(05):39-40.[2] 周治国.GPU CPU谁革谁的命[J].上海信息化，2008，（6）[3]https://www.nvidia.cn/object/what-is-gpu-computing-cn.html[4]钟联波.GPU与CPU的比较分析[J].技术与市场,2009,16(09):13-14.[5]李红辉,刘冬冬,杨芳南.CPU+GPU异构并行计算技术研究[J].信息系统工程,2018(05):39-40.[6]邓彦伶.基于GPU的异构计算技术在超级计算领域的现状及发展展望[J].电脑迷,2017(08):201.[7]Andy Patrizio. GPU:为何对HPC和AI越来越重要？[N]. 计算机世界,2018-08-06(005).[8]曹璐云.AMD和NVIDIA两家公司GPU架构由分到合发展综述[J].信息与电脑(理论版),2016(11):58-59+99.[9]陈云海.Nvidia GPU核心架构技术演进分析[J].广东通信技术,2018(11):52-58+77.[10]寒意.以深度学习为目标,NVIDIA发布首款Volta架构GPU[J].华东科技,2017(05):14.","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"https://tomsworkspace.github.io/tags/GPU/"},{"name":"CPU与GPU","slug":"CPU与GPU","permalink":"https://tomsworkspace.github.io/tags/CPU%E4%B8%8EGPU/"},{"name":"图形图像处理器","slug":"图形图像处理器","permalink":"https://tomsworkspace.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%99%A8/"}]},{"title":"中国智能硬件调研报告","slug":"中国智能硬件调研报告","date":"2019-12-07T06:53:27.000Z","updated":"2020-01-15T09:20:15.815Z","comments":true,"path":"2019/12/07/中国智能硬件调研报告/","link":"","permalink":"https://tomsworkspace.github.io/2019/12/07/%E4%B8%AD%E5%9B%BD%E6%99%BA%E8%83%BD%E7%A1%AC%E4%BB%B6%E8%B0%83%E7%A0%94%E6%8A%A5%E5%91%8A/","excerpt":"","text":"一、介绍&emsp;&emsp;随着万物互联时代的到来,硬件智能化成为全社会的共识,在此背景下,智能硬件成为全球发展 最快、市场潜力最大的行业之一。由于政府、科技企业的高度重视和大力投入,智能硬件产业得到了快速发展,出货量、装机量和市场规模显著提升。 &emsp;&emsp;随着智能化、互联网化与社会经济、人民生活的结合日益紧密，以可穿戴设备、智能家居设备、机器人等为代表的智能硬件正在蓬勃兴起，掀起新一轮的终端产业变革。近几年，相关产品形态快速创新，向生产生活各领域渗透，并通过对传统设备的智能化改造，大大提升原有产业附加值、延伸产业链，加速推动新的生产组织模式变革。 &emsp;&emsp;根据市场研究机构数据,2015年我国智能硬件市场规模达到2750亿元,2016年达到3310亿元, 同比增长21%。2018年,我国智能硬件产业规模超过4700亿元,接近5000亿元,同比增速维持15%以上,产业发展格局初步形成,产业应用水平明显提升。智能硬件在大众消费市场逐步普及,在全球市场将具有较强国际竞争力。[1] 二、什么是智能硬件&emsp;&emsp;智能硬件是继智能手机之后的一个科技概念，通过软硬件结合的方式，对传统设备进行改造，进而让其拥有智能化的功能。智能化之后，硬件具备连接的能力，实现互联网服务的加载，形成“云端”的典型架构，具备了大等附加价值。 &emsp;&emsp;智能硬件是一个科技概念，指通过将硬件和软件相结合对传统设备进行智能化改造。而智能硬件移动应用则是软件，通过应用连接智能硬件，操作简单，开发简便，各式应用层出不穷，也是企业获取用户的重要入口。 &emsp;&emsp;改造对象可能是电子设备，例如手表、电视和其他电器；也可能是以前没有电子化的设备，例如门锁、茶杯、汽车甚至房子。 &emsp;&emsp;智能硬件已经从可穿戴设备延伸到智能电视、智能家居、智能汽车、医疗健康、智能玩具、机器人等领域。比较典型的智能硬件包括Google Glass、三星Gear、FitBit、麦开水杯、咕咚手环、Tesla、乐视电视等。 &emsp;&emsp;智能硬件是以平台性底层软硬件为基础，以智能传感互联、人机交互、新型显示及大数据处理等新一代信息技术为特征，以新设计、新材料、新工艺硬件为载体的新型智能终端产品及服务。随着技术升级、关联基础设施完善和应用服务市场的不断成熟，智能硬件的产品形态从智能手机延伸到智能可穿戴、智能家居、智能车载、医疗健康、智能无人系统等，成为信息技术与传统产业融合的交汇点。[2] 三、典型产品简介&emsp;&emsp;目前在智能硬件行业比较大的一些公司有谷歌，苹果，百度，奇虎360，JAWBONE NIKE，Microsoft，三星，华为，小米等。对于智能硬件应用领域大致有如下几种：智能家居，智能可穿戴设备，智能交通，智能医疗以及其他领域的智能硬件。 （一）智能家居&emsp;&emsp;智能家居是在互联网影响之下物联化的体现。智能家居通过物联网技术将家中的各种设备（如音视频设备、照明系统、窗帘控制、空调控制、安防系统、数字影院系统、影音服务器、影柜系统、网络家电等）连接到一起，提供家电控制、照明控制、电话远程控制、室内外遥控、防盗报警、环境监测、暖通控制、红外转发以及可编程定时控制等多种功能和手段。与普通家居相比，智能家居不仅具有传统的居住功能，兼备建筑、网络通信、信息家电、设备自动化，提供全方位的信息交互功能，甚至为各种能源费用节约资金。[3] &emsp;&emsp;比较典型的智能家居产品如百度近期发布的小度在家1S. &emsp;&emsp;小度在家1S采用全球顶级设计与全新硬件配置，它由来自加州的Sonos智能音响工业设计师Wai-loong Lim操刀设计，造型典雅，自然融入家居，线条简洁，稳重大气；在音质方面，通过18项硬件升级和28项算法改进，为用户带来更澎湃的音效；相比小度在家，小度在家1S无线数据传输速度提升100%，视频通话更清晰、追剧听歌更流畅，家庭影音娱乐体验更上一层楼。 &emsp;&emsp;在内容资源上，小度在家1S通过与爱奇艺、QQ音乐、蜻蜓FM、斗鱼等多品牌合作，已拥有千万级音乐曲库，海量视频内容及优质的有声及儿童教育资源，不止于此，小度在家1S还最新引入了百度视频资源，并与喜马拉雅达成合作，接入喜马拉雅开放平台全量内容，涵盖喜马拉雅最优质的1亿+精品音频内容，为用户提供更丰富的声音内容收听体验。 &emsp;&emsp;值得一提的是，小度在家1S儿童模式全面升级，拥有行业最优儿童唤醒识别、儿童专属TTS音色和对话以及更适合儿童的交互界面，让孩子全程交互无障碍。儿童模式还专为孩子再增加三重保护：时长保护、距离保护和内容保护，不论是孩子离屏幕太近还是观看时间过长，小度都会及时提醒，同时会过滤掉不宜儿童视听的内容，呵护孩子的身心健康。 （二）智能可穿戴设备&emps;&emsp;“穿戴式智能设备”是应用穿戴式技术对日常穿戴进行智能化设计、开发出可以穿戴的设备的总称，如眼镜、手套、手表、服饰及鞋等。广义穿戴式智能设备包括功能全、尺寸大、可不依赖智能手机实现完整或者部分的功能，例如：智能手表或智能眼镜等，以及只专注于某一类应用功能，需要和其它设备如智能手机配合使用，如各类进行体征监测的智能手环、智能首饰等。随着技术的进步以及用户需求的变迁，可穿戴式智能设备的形态与应用热点也在不断的变化。 &emsp;&emsp;典型的智能可穿戴设备如小米手环。 &emsp;&emsp;小米手环的主要功能包括查看运动量，监测睡眠质量，智能闹钟唤醒等。可以通过手机应用实时查看运动量，监测走路和跑步的效果，还可以通过云端识别更多的运动项目。 &emsp;&emsp;小米手环能够自动判断是否进入睡眠状态，分别记录深睡及浅睡并汇总睡眠时间，帮助用户监测自己的睡眠质量。 &emsp;&emsp;小米手环配备了低功耗蓝牙芯片及加速传感器，待机可达30天。另外，它支持IP67级别防水防尘，意味着日常生活，甚至是洗澡都无须摘下。 （三）智能交通&emsp;&emsp;智能交通：智能交通是一个基于现代电子信息技术面向交通运输的服务系统。它的突出特点是以信息的收集、处理、发布、交换、分析、利用为主线，为交通参与者提供多样性的服务。 &emsp;&emsp;智能交通的发展跟物联网的发展是离不开的，只有物联网技术概念的不断发展，智能交通系统才能越来越完善。智能交通是交通的物联化体现。 &emsp;&emsp;21世纪将是公路交通智能化的世纪，人们将要采用的智能交通系统，是一种先进的一体化交通综合管理系统。在该系统中，车辆靠自己的智能在道路上自由行驶，公路靠自身的智能将交通流量调整至最佳状态，借助于这个系统，管理人员对道路、车辆的行踪将掌握得一清二楚。 &emsp;&emsp;如百度地图今年推出的智能停车系统。 &emsp;&emsp;该系统不仅可以有效地解决当地车主出行“停车难”的问题，而且也为银川的智能城市建设提供了助力，为其它城市的交通问题提供了参考。据悉，此次百度在银川推出的智能停车系统，基于多维停车大数据之上，然后进一步结合政府的实时监控，实现了停车场资源的规范化、智能化，甚至可以平均减少车主寻找车位10%的停车时间。同时该系统不仅可以方便驾驶员导航出行时的停车位，甚至还能在停车后准确的找到车辆的停放位置。 &emsp;&emsp;该系统可在一定程度上查询到目的地附近的停车位，以及了解其车位的使用情况，如果车位紧张，系统将自动提醒并及时提供替换方案。甚至驾驶员还能够使用停车助手，提前预约车位并在地图上一键发起导航，再也不用担心遇见停车位正好停满的情况。 &emsp;&emsp;同时在陌生的停车场停车，很容易发生找不到车辆停放位置的尴尬情况。如今在百度地图智能停车系统的帮助之下，驾驶员在抵达车位并一键降锁之后，系统将自动记录车辆停放位置。所以在反向寻车时，车主只需用百度地图一键发起寻车，即可在步行导航的指引下轻松找到车辆的停放位置。 （四）智能医疗&emsp;&emsp;智能医疗是通过打造健康档案区域医疗信息平台，利用最先进的物联网技术，实现患者与医务人员、医疗机构、医疗设备之间的互动，逐步达到信息化。 在不久的将来医疗行业将融入更多人工智慧、传感技术等高科技，使医疗服务走向真正意义的智能化，推动医疗事业的繁荣发展。在中国新医改的大背景下，智能医疗正在走进寻常百姓的生活。 &emsp;&emsp;典型产品如结合了人工智能技术的达·芬奇手术机器人系统。 &emsp;&emsp;它主要分为两个部分：手术台和由医生远程操控的系统终端。在手术台设有一个拥有三个机械臂的机器人，由它负责进行手术，精准度和灵活性都比人类医生来得好，尤其适用于高难度的手术。而在系统终端，医生所操控的计算机拥有可拍摄二维图像的摄像机，并将人体内的情况利用三维图像清晰地显示出来，让医生可以监控整个手术过程。目前这款手术机器人已经协助完成了近300万例的手术。 四、特点&emsp;&emsp;各大厂商纷纷在智能硬件领域长线布局,智能硬件产业飞速发展,主流产品如智能手环、智能 手表、智能插座、智能路由器、智能电视、智能家居与智能健康、智能驾驶汽车、消费级无人机等产品等纷纷涌现,智能硬件开始向大众市场渗透。智能硬件是一个快速发展的产业领域,新产品、 新技术、新应用、新模式层出不穷,产业边界在不断变化,并呈现以下主要特点[4]。 &emsp;&emsp;根据目前的产业状况,以产品的形态来看智能硬件包括可穿戴设备、智能家居、智能车载、智能无人系统、智慧健康以及其他面向消费和工业领域的智能化产品。智能硬件在本质上,是基于智能芯片、大规模集成电路、互联网及移动互联网、软件与应用、大数据和云计算、人工智能和虚拟现实、新能源和新材料以及生物技术等前沿技术领域的发展,跨界融合而形成的全新的产品形态。 &emsp;&emsp;目前,发达国家均认可智能硬件是抢占未来信息化制高点的重要的途径和战略举措。在国际上, 以苹果、谷歌、微软、Facebook、特斯拉、高通等为代表的国际巨头,投入大量资源进行智能硬件技术研发和市场培育;在国内,百度、阿里、腾讯、小米、京东、乐视、360、华为、联想等企业也投入巨资构建自己的产业生态体系,快速推动智能硬件产业的发展。当前,全球正处于万物互联时代,物联网社会已经到来。随着前沿技术发展、企业和资本的广泛参与,智能硬件正快速的拓展到经济与社会的各个领域,释放和催生工业、农业、服务业、节能 环保、商贸流通、交通能源、公共安全、社会事业、城市管理等各个领域的新需求。智能硬件通过产生全新的生产制造和商业应用模式,激发大众创业、万众创新活力,大幅提高产业发展的质量和效率,为经济结构调整和产业转型升级创造了全新的发展空间,形成新的经济增长极。 &emsp;&emsp;伴随各大领域企业竞相构建智能硬件生态,行业发展已从单品之争转向平台之争,平台的重要 性日益凸显。在智能硬件底层软硬件技术公共服务平台方面,国内外直接或间接竞争对手有苹果智能家居平台HomeKit和车载信息平台CarPlay、三星智能家居平台SmartHome、Google智能家居系统Brillo和车载信息平台Android Auto、百度智能健康设备平台dulife、小米生活服务平台 MIUI 6、阿里巴巴物联网平台、腾讯“QQ 物联”智能硬件开放平台、杰升科技机智云等。 五、发展现状（一）智能硬件产品形成一定的比较优势&emsp;&emsp;可穿戴设备发展较快，企业保持全球前列。从全球市场看，据IDC最新数据显示，2016年第三季度全球可穿戴设备出货量排名中，小米公司占据第二，市场份额约为16.5%。我国企业步步高凭借儿童智能手表等产品，出货量也处于全球领先地位。从国内市场看，2016年第二季度中国可穿戴设备市场出货量为954万台，同比增长81.4%。中国可穿戴设备市场的高速增长主要依靠本土厂商在细分市场的精耕细作，及其综合实力的快速成长，这主要体现在4个方面：产品由硬向软的转变；功能由小到大的成长；渠道由点向面的覆盖；市场由内向外的扩张。智能家居稳步增长，应用标准和平台逐步形成。由于智能电视渗透率即将步入瓶颈，增长速度逐步放缓，而小家电及其他智能家居产品还未进入爆发期，因此国内智能家居市场总体仍将保持增长，但是增长速度在缓慢下降。家居平台和应用标准逐步形成，我国企业海尔、阿里巴巴、百度、小米等均已建立不同类型 的智能家居应用平台，如海尔的平台具备较完善的软 件和硬件开发API标准、大数据平台、开放的SDK等。 此外，互联网企业在布局智能家居时都在寻求适合的 跨界模式，与传统家居跨界合作频繁，以求相互取长补短增强竞争力。 我国无人机企业一家独大，带动形成成熟的区域产业链。我国企业大疆科技占据全球无人机市场约70%的份额，其中80%销量出口国外。核心技术方面，大疆自主研发的无人机飞控系统和航拍设备的性能业界领先，除自用外，还为下游制造企业提供飞控系统、任务设备和动力设备，加强产业主导能力的大疆的快速发展带动珠三角地区形成完整的无人机产业链，涵盖机架、电池、电机、云台、飞控系统、整机集成、投资、供应链服务、爱好者社区等关键节点，并辐射北京、上海。但如今Intel、高通、3DRobotic等国际企业布局加 快，加强了在消费级无人机芯片、飞控技术上的研发，同时“效仿”安卓的产业生态策略，以基础技术开源为手段加快对产业链下游的控制，我国无人机产业面临开源技术生态竞争，存在控制力下降的风险。 （二）核心技术环节仍然薄弱&emsp;&emsp;MCU与短距离芯片仍处于追赶阶段，低功率广域网芯片抢占先机。在MCU方面，中国本土的MCU供应商在2016年稳步增长，代表企业如中颍、Gigadevice 和晟矽微都保持14%的年增长速度，但国产MCU主要仍以低端4/8位单片机为主，大部分仍用于消费电子、 家电、水表等专用市场。在短距离通信芯片方面，2015年国内Wi-Fi芯片迅速增长，国内大多厂商均成立于2000年以后，以中小型企业为主，成熟应用产品仍较少。在NB-IoT方面，我国相关技术发展较早，并利用先发优势，计划推出相应芯片，如华为海思作为 NB-Io主导方，计划推出NB-IoT商用芯片。新型传感器缺乏布局，产品性能与国外差距明显。我国传感器总体水平较国外差距较大，对于新型传感器缺乏布局。运动传感器普及度较高，ST、博世等国际大厂技术领先（性能稳定）、规模大（ST累计90亿 颗）。而国内传感器品类单一、规模小，技术水平总体较低。如格科威和豪威CMOS传感器出货量占据全球一半的市场份额，但是市场规模合计只有15%，充分体现我国CMOS传感器主要面向低端市场，缺少高端产品。此外，在光线、温湿度、距离、心率传感器等趋势性 应用领域基本空白。AMOLED产业为韩国三星垄断，柔性显示发展较慢。在AMOLED方面，小尺寸AMOLED面板三星的市占率逾95%，为打破垄断现状，国内厂商在此领域纷纷布局，京东方（2013年年底）、和辉光电（2014年年底）成功量产，华星光电、国显光电、天马、信利等企业也积极建设AMOLED生产线。在柔性显示方面，三星 显示器主宰了市场，国内企业仍处于追赶状态，产业链相对不够成熟，相关材料及设备均要依赖进口，人才和技术仍是弱项。 六、未来发展趋势(一)随着国家战略性扶持力度的加大，智能硬件的发展将呈现出不断增长的趋势[5]。&emsp;&emsp;在中央及地方政策不断完善。国家出台一系列政策，成立联盟或产业基地，发力支持智能硬件产业的发展。包括国务院《关于积极推进“互联网+”行动的指导 意见》、发改委《“互联网+”人工智能3年行动实施方 案》、工信部《新兴智能硬件产业创新发展专项行动》、北京成立中关村智能硬件联盟、上海成立“科技50”智能硬件产业基地等。此外，产业相关标准正在完善，包括《智能硬件白皮书》、《中国可穿戴联盟标准》等。 （二）智能机器人的使用将会是未来发展的重头戏。&emsp;&emsp;现在智能产品普及率高，人们享受到了科技带给人们的便利。但是，相对于智能手表，智能手环等智能产品而言，智能机器人的使用还不是很广泛，普及性不高。国外科学家们正在努力开发智能机器人，使之成为未来智能硬件产业的一个“开拓者”。在未来可能会面临一种情况，如：繁重的家务活、精细的手术、有危险的技术操作等一些体力劳动工作，都可以依靠机器人来完成，甚至一些脑力活动也能被机器人所取代。在未来，智能机器人的使用也将会实现爆炸式的增长。相关数据显示，在 2014 年，美国、德国等国家每10个工业人员，就会使用1台以上工业机器人。全球工业已经进入以大数据、云计算、智能机器人和 3D 打印技术等为典型代表的“第四次工 业革命”[6]。在未来，智能机器人将在工业领域大展身手。 七、参考文献[1]赛迪智库. 智能硬件产业发展白皮书[N]. 中国计算机报,2018-12-24(008).[2]2019-2023年中国智能硬件行业深度调研及投资前景预测报告.[3]李天祥编. ANDROID物联网开发细致入门与最佳实践[M]. 2016 第14页.[4]AVC.2016上半年智能硬件行业发展总结与趋势展望[R]. AVC,2016.[5]易观智库.中国创新智能硬件市场发展专题研究报告[R]. 易观智库,2015.[6]李碧生.把握智能制造机遇 推动工业转型升级——西安工业经济智能制造革命浅析[J].经济研究导刊，2018，(19)：46-47.","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"智能硬件","slug":"智能硬件","permalink":"https://tomsworkspace.github.io/tags/%E6%99%BA%E8%83%BD%E7%A1%AC%E4%BB%B6/"}]},{"title":"Linux-Arm page table","slug":"Linux-Arm-page-table","date":"2019-11-26T08:44:04.000Z","updated":"2020-01-15T09:30:26.785Z","comments":true,"path":"2019/11/26/Linux-Arm-page-table/","link":"","permalink":"https://tomsworkspace.github.io/2019/11/26/Linux-Arm-page-table/","excerpt":"","text":"一．多级页表的概念&emsp;&emsp;介绍页表之前，我们先来回顾一个操作系统里的基本概念，虚拟内存。 1.1 虚拟内存&emsp;&emsp;在用户的视角里，每个进程都有自己独立的地址空间，A进程的4GB和B进程4GB是完全独立不相关的，他们看到的都是操作系统虚拟出来的地址空间。但是呢，虚拟地址最终还是要落在实际内存的物理地址上进行操作的。操作系统就会通过页表的机制来实现进程的虚拟地址到物理地址的翻译工作。其中每一页的大小都是固定的。页表管理有两个关键点，分别是页面大小和页表级数。 1.2 页面大小&emsp;&emsp;在Linux下，我们通过如下命令可以查看到当前操作系统的页大小 # getconf PAGE_SIZE 1.3 页表级数&emsp;&emsp;页表级数越少，虚拟地址到物理地址的映射会很快，但是需要管理的页表项会很多，能支持的地址空间也有限。相反页表级数越多，需要的存储的页表数据就会越少，而且能支持到比较大的地址空间，但是虚拟地址到物理地址的映射就会越慢。 &emsp;&emsp;举个例子。如果想支持32位的操作系统下的4GB进程虚拟地址空间，假设页表大小为4K，则共有2的20次方页面。如果采用速度最快的1级页表，对应则需要2的20次方个页表项。一个页表项假如4字节，那么一个进程就需要（10485764=4M）的内存来存页表项。如果是采用2级页表，则只需要页目录1024个，页表项1024个，总共2028个页表管理条目，（20484=）8k就可以支持起4GB的地址空间转换。更何况操作系统需要支持的可是64位地址空间，而且要支持成百上千的进程，这个开销会大道不可忍。所以每个操作系统制定页表级数的时候都是在映射速度和页表占用空间中取折中。 &emsp;&emsp;Linux在v2.6.11以后，最终采用的方案是4级页表，分别是： PGD：page Global directory(47-39), 页全局目录 PUD：Page Upper Directory(38-30)，页上级目录 PMD：page middle directory(29-21)，页中间目录 PTE：page table entry(20-12)，页表项 &emsp;&emsp;这样，一个64位的虚拟空间，就需要：2^9 个PGD + 2^9 个PUD + 2^9 个PMD + 2^9 个PTE = 2048个页表数据结构。现在的页表数据结构被扩展到了8byte。仅仅需要(2048*8=)16K就可以支持起(2^48 =)256T的进程地址空间。 PGD: Page Global Directory &emsp;&emsp;Linux系统中每个进程对应用户空间的pgd是不一样的，但是linux内核的pgd是一样的。当创建一个新的进程时，都要为新进程创建一个新的页面目录PGD，并从内核的页面目录swapper_pg_dir中复制内核区间页面目录项至新建进程页面目录PGD的相应位置，具体过程如下do_fork()-&gt;copy_mm()-&gt;mm_init()-&gt;pgd_alloc()-&gt;set_pgd_fast()-&gt;get_pgd_slow()-&gt;memcpy(&amp;PGD+USER_PTRS_PER_PGD,swapper_pg_dir+USER_PTRS_PER_PGD,(PTRS_PER_PGD-USER_PTRS_PER_PGD)*sizeof(pgd_t))这样一来，每个进程的页面目录就分成了两部分，第一部分为“用户空间”，用来映射其整个进程空间（0x0000 0000－0xBFFF FFFF）即3G字节的虚拟地址；第二部分为“系统空间”，用来映射（0xC000 0000－0xFFFF FFFF）1G字节的虚拟地址。可以看出Linux系统中每个进程的页面目录的第二部分是相同的，所以从进程的角度来看，每个进程有4G字节的虚拟空间，较低的3G字节是自己的用户空间，最高的1G字节则为与所有进程以及内核共享的系统空间。每个进程有它自己的PGD( Page Global Directory)，它是一个物理页，并包含一个pgd_t数组。 PTE: 页表项（page table entry） &emsp;&emsp;PGD中包含若干PUD的地址，PUD中包含若干PMD的地址，PMD中又包含若干PT的地址。每一个PTE页表项指向一个页框，也就是一个实际的物理页面。 1.4 页表带来的问题&emsp;&emsp;虽然16K的页表数据支持起了256T的地址空间寻址。但是，这也带来了额外的问题，页表是存在内存里的。那就是一次内存IO光是虚拟地址到物理地址的转换就要去内存查4次页表，再算上真正的内存访问，竟然需要5次内存IO才能获取一个内存数据! TLB应运而生 &emsp;&emsp;和CPU的L1、L2、L3的缓存思想一致，既然进行地址转换需要的内存IO次数多，且耗时。那么干脆就在CPU里把页表尽可能地cache起来不就行了么，所以就有了TLB(Translation Lookaside Buffer)，专门用于改进虚拟地址到物理地址转换速度的缓存。其访问速度非常快，和寄存器相当，比L1访问还快。有了TLB之后，CPU访问某个虚拟内存地址的过程如下： 1.CPU产生一个虚拟地址 2.MMU从TLB中获取页表，翻译成物理地址 3.MMU把物理地址发送给L1/L2/L3/内存 4.L1/L2/L3/内存将地址对应数据返回给CPU&emsp;&emsp;由于第2步是类似于寄存器的访问速度，所以如果TLB能命中，则虚拟地址到物理地址的时间开销几乎可以忽略。 二．内核页表和进程页表&emsp;&emsp;内核页表：即主内核页表，在内核中其实就是一段内存，存放在主内核页全局目录init_mm.pgd(swapper_pg_dir)中，硬件并不直接使用。 &emsp;&emsp;进程页表：每个进程自己的页表，放在进程自身的页目录task_struct.pgd中。 &emsp;&emsp;在保护模式下，从硬件角度看，其运行的基本对象为“进程”(或线程)，而寻址则依赖于“进程页表”，在进程调度而进行上下文切换时，会进行页表的切换：即将新进程的pgd(页目录)加载到CR3寄存器中。 &emsp;&emsp;1、 内核页表中的内容为所有进程共享，每个进程都有自己的“进程页表”，“进程页表中映射的线性地址包括两部分：用户态，内核态。 &emsp;&emsp;其中，内核态地址对应的相关页表项，对于所有进程来说都是相同的(因为内核空间对所有进程来说都是共享的)，而这部分页表内容其实就来源于“内核页表”，即每个进程的“进程页表”中内核态地址相关的页表项都是“内核页表”的一个拷贝。 &emsp;&emsp;2、“内核页表”由内核自己维护并更新，在vmalloc区发生page fault时，将“内核页表”同步到“进程页表”中。以32位系统为例，内核页表主要包含两部分：线性映射区,vmalloc区。 &emsp;&emsp;其中，线性映射区即通过TASK_SIZE偏移进行映射的区域，对32系统来说就是0-896M这部分区域，映射对应的虚拟地址区域为TASK_SIZE-TASK_SIZE+896M。这部分区域在内核初始化时就已经完成映射，并创建好相应的页表，即这部分虚拟内存区域不会发生page fault。 &emsp;&emsp;vmalloc区，为896M-896M+128M，这部分区域用于映射高端内存，有三种映射方式：vmalloc、固定、临时。以vmalloc为例(最常使用)，这部分区域对应的线性地址在内核使用vmalloc分配内存时，其实就已经分配了相应的物理内存，并做了相应的映射，建立了相应的页表项，但相关页表项仅写入了“内核页表”，并没有实时更新到“进程页表中”，内核在这里使用了“延迟更新”的策略，将“进程页表”真正更新推迟到第一次访问相关线性地址，发生page fault时，此时在page fault的处理流程中进行“进程页表”的更新。 2.1 主内核页表 swapper_pg_dir&emsp;&emsp;主内核页表负责维护内核空间的页表映射，完成后的内核空间主页表映射如下图 (每一项映射1M空间，lk项刚好映射4G虚拟空间)swapper_pg_dir用于存放内核PGD页表的地方，赋给内核页表init_mm.pgd。swapper_pd_dir的大小为16KB，对应的虚拟地址空间是从0xc0004000 - 0xc0008000，物理地址空间是0x6000400~0x60008000。swapper_pg_dir被定义了绝对地址，在arch/arm/kernel/head.S中定义。 2.2 用户进程页表2.2.1 进程如何使用内存&emsp;&emsp;毫无疑问，所有进程（执行的程序）都必须占用一定数量的内存，它或是用来存放从磁盘载入的程序代码，或是存放取自用户输入的数据等等。不过进程对这些内存的管理方式因内存用途不一而不尽相同，有些内存是事先静态分配和统一回收的，而有些却是按需要动态分配和回收的。对任何一个普通进程来讲，它都会涉及到5种不同的数据段。 &emsp;&emsp;代码段：代码段是用来存放可执行文件的操作指令，也就是说是它是可执行程序在内存中的镜像。代码段需要防止在运行时被非法修改，所以只准许读取操作，而不允许写入（修改）操作——它是不可写的。 &emsp;&emsp;数据段：数据段用来存放可执行文件中已初始化全局变量，换句话说就是存放程序静态分配的变量和全局变量。 &emsp;&emsp;BSS段：BSS段包含了程序中未初始化的全局变量，在内存中 bss段全部置零。 &emsp;&emsp;堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减） &emsp;&emsp;栈：栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。 2.2.2 进程页表如何创建进程的内核页全局目录的装载过程 &emsp;&emsp;do_fork()-&gt;copy_process()-&gt;copy_mm()(如果是fork一个内核线程kernel thread的话，内核线程将会直接使用当前普通进程的页表集，内核线程并不拥有自己的页表集)-&gt;dup_mm()-&gt;mm_init()-&gt;mm_alloc_pgd()-&gt;pgd_alloc &emsp;&emsp;pgd_ctor(mm, pgd) //将swapper_pg_dir全局页目录（部分后256项–即内核最后1G的虚拟地址,这里指的是内核的页表）拷到pgd里，则可以看出，linux下所有进程的内核页全局目录是一样的，都是swapper_pg_dir里最后的1/4的内容，而每个进程的用户态的页表确是不同的，所以在dup_mmap会去将父进程的页表一项一项的爬出来设置为当前进程的页表。 进程的用户态地址页拷贝 &emsp;&emsp;dup_mmap()函数实现页表映射的拷贝 &emsp;&emsp;页表的复制 copy_page_range() copy_pud_range() copy_pmd_range() copy_pte_range（） &emsp;&emsp;cr3寄存器的加载 &emsp;&emsp;cr3寄存器的加载是在进程调度的时候更新的，具体如下schedule()-&gt;context_switch()-&gt;switch_mm()-&gt;load_cr3(next-&gt;pgd)。load_cr3加载的是mm_struct-&gt;pgd，即线性地址，而实际上加裁到cr3寄存器的是实际的物理地址write_cr3(pa(pgdir));在装载cr3寄存器时将线性地址通过pa转换成了物理地址了，所以cr3寄存器是装的是实实在在的物理地址。 2.2.3 用户进程页如何分配 &emsp;&emsp;bss段：BSS段属于静态内存分配。通常是指用来存放程序中未初始化的全局变量和未初始化的局部静态变量。未初始化的全局变量和未初始化的局部静态变量默认值是0，本来这些变量也可以放到data段的，但是因为他们都是0，所以为他们在data段分配空间并且存放数据0是没有必要的。程序在运行时，才会给BSS段里面的变量分配内存空间。在目标文件(*.o)和可执行文件中，BSS段只是为未初始化的全局变量和未初始化的局部静态变量预留位置而已，它并没有内容，所以它不占据空间。section table中保存了BSS段（未初始化的全局变量和未初始化的局部静态变量）内存空间大小总和。（objdump -h *.o 命令可以看到） &emsp;&emsp;data段：数据段（datasegment）通常是指用来存放程序中已初始化的全局变量和已初始化的静态变量的一块内存区域。数据段属于静态内存分配。 &emsp;&emsp;text段：代码段（codesegment/textsegment）通常是指用来存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于只读，某些架构也允许代码段为可写，即允许修改程序。在代码段中，也有可能包含一些只读的常数变量，例如字符串常量等。 &emsp;&emsp;rodata段：存放的是只读数据，比如字符串常量，全局const变量 和 #define定义的常量。 &emsp;&emsp;heap堆：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减） &emsp;&emsp;stack栈：是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。 &emsp;&emsp;创建进程，虚拟地址和物理地址之间的映射关系 &emsp;&emsp;上面的图说明：同一个变量，地址相同，其实是虚拟地址相同，内容不同其实是被映射到了不同的物理地址! &emsp;&emsp;过程：当访问虚拟内存时，会访问MMU（内存管理单元）去匹配对应的物理地址，而如果虚拟内存的页并不存在于物理内存中，会产生缺页中断，从磁盘中取得缺的页放入内存，如果内存已满，还会根据某种算法将磁盘中的页换出。（MMU中存储页表，用来匹配虚拟内存和物理内存）","categories":[{"name":"Linux kernel","slug":"Linux-kernel","permalink":"https://tomsworkspace.github.io/categories/Linux-kernel/"}],"tags":[{"name":"linux-Arm","slug":"linux-Arm","permalink":"https://tomsworkspace.github.io/tags/linux-Arm/"},{"name":"page table","slug":"page-table","permalink":"https://tomsworkspace.github.io/tags/page-table/"},{"name":"页表","slug":"页表","permalink":"https://tomsworkspace.github.io/tags/%E9%A1%B5%E8%A1%A8/"},{"name":"PGD PTE","slug":"PGD-PTE","permalink":"https://tomsworkspace.github.io/tags/PGD-PTE/"},{"name":"四级页表","slug":"四级页表","permalink":"https://tomsworkspace.github.io/tags/%E5%9B%9B%E7%BA%A7%E9%A1%B5%E8%A1%A8/"}]},{"title":"DLL-lose","slug":"DLL-lose","date":"2019-11-21T07:55:47.000Z","updated":"2020-01-15T09:32:40.590Z","comments":true,"path":"2019/11/21/DLL-lose/","link":"","permalink":"https://tomsworkspace.github.io/2019/11/21/DLL-lose/","excerpt":"&emsp;&emsp;在安装某些软件，我们正准备开开心心地打开，哦豁，duang的一声弹出一个框框。就像下面这样。 这时候是不是一筹莫展呢？别灰心，这类问题大多数还是能解决的。","text":"&emsp;&emsp;在安装某些软件，我们正准备开开心心地打开，哦豁，duang的一声弹出一个框框。就像下面这样。 这时候是不是一筹莫展呢？别灰心，这类问题大多数还是能解决的。 1. DLL文件的概念1.1 什么是dll文件&emsp;&emsp;DLL(Dynamic Link Library)文件为动态链接库文件，又称“应用程序拓展”，是软件文件类型。在Windows中，许多应用程序并不是一个完整的可执行文件，它们被分割成一些相对独立的动态链接库，即DLL文件，放置于系统中。当我们执行某一个程序时，相应的DLL文件就会被调用。一个应用程序可使用多个DLL文件，一个DLL文件也可能被不同的应用程序使用，这样的DLL文件被称为共享DLL文件。 &emsp;&emsp;在 Windows操作系统中，每个程序都可以使用该 DLL 中包含的功能来实现“打开”对话框。 &emsp;&emsp;DLL文件中存放的是各类程序的函数(子过程)实现过程，当程序需要调用函数时需要先载入DLL，然后取得函数的地址，最后进行调用。使用DLL文件的好处是程序不需要在运行之初加载所有代码，只有在程序需要某个函数的时候才从DLL中取出。这有助于促进代码重用和内存的有效使用。 1.2 使用dll文件的好处 实现模块化 &emsp;&emsp;通过使用 DLL，程序可以实现模块化，由相对独立的组件组成。例如，一个记账程序可以按模块来销售。可以在运行时将各个模块加载到主程序中（如果安装了相应模块）。因为模块是彼此独立的，所以程序的加载速度更快，而且模块只在相应的功能被请求时才加载。另外，使用DLL文件还可以减小程序的体积。 便于应用更新 &emsp;&emsp;可以更为容易地将更新应用于各个模块，而不会影响该程序的其他部分。例如，您可能具有一个工资计算程序，而税率每年都会更改。当这些更改被隔离到 DLL 中以后，您无需重新生成或安装整个程序就可以应用更新。 2. dll文件丢失的解决办法&emsp;&emsp;当某个程序或 DLL 使用其他 DLL 中的 DLL 函数时，就会创建依赖项。因此，该程序就不再是独立的，并且如果该依赖项被损坏，该程序就可能遇到问题。就会产生类似于.dll文件丢失这样的问题。 2.1 dll文件丢失的原因&emsp;&emsp;出现DLL文件丢失一般出现在Windows系统中。产生dll文件丢失的原因有很多。大概总结了一下，有以下的几种： （1）程序依赖的 DLL文件升级到新版本 （2）未安装程序需要的DLL文件 （3）依赖 DLL 被其早期版本覆盖 （4）从计算机中删除了依赖 DLL （5）由dll文件命名引发的丢失 2.2 解决办法&emsp;&emsp;解决dll丢失问题的方法有一下几种，不过并不是所有的解决方法都能解决问题。在选择解决问题的方法之前先找到产生丢失dll的具体原因是什么，还有丢失的dll文件是什么类型的。然后再对症下药，方能药到病除。 丢失文件的类型： &emsp;&emsp;丢失的dll文件是与编程语言和系统环境有关的dll文件。一般出现在microsoft自己的软件运行时出现，比如许多微软自己开发的开发工具，VS ，vc++,Qt之类的程序，可能的原因是(1)(2)(3)(4)。 &emsp;&emsp;丢失的dll文件是与具体程序相关的，非microsoft相关的，一般出现在一个刚安装的程序或者不需要安装可以直接运行的exe文件运行时出现的。还有就是网上下载的所谓的破解版的软件最容易出现这种问题。出现的原因可能是(2)(4)。 解决方法： 方法1：下载一键式修复工具 &emsp;&emsp;有许多人开发了专门针对这类dll丢失问题的一键式修复工具。如 Diretx工具 &emsp;&emsp;这是一个一键批量检测当前系统丢失的dll文件并进行自动修复，使用方法是最简单的。只能解决第一类问题中的少部分问题，可以用来修复那些系统相关的dll文件。使用方法 方法2：下载丢失的对应的DLL文件并放到对应的目录 &emsp;&emsp;将dll文件复制到Windows系统目录或者复制到程序安装目录中。针对报丢失的dll文件，按照名字去搜索对应的DLL文件下载，并放置在对应的目录。一般第一类的问题，和系统相关的dll文件放在系统对应的目录下。(32位系统在 C:\\Windows\\System32,64位系统放在C：\\Windows\\SysWOW64下）和程序相关的放在对应程序安装目录下。一般是这样，但是也不是绝对的，也有的程序丢失的dll放在系统目录下的，比如有的.exe程序。 &emsp;&emsp;下面给出一些可以搜索下载dll文件的网址： Dll-files https://www.zhaodll.com/ Dll之家 脚本之家 DLL文件下载器或者https://gitee.com/wyatthuang/dll_downloader &emsp;&emsp;这个是一个爬取工具。原理是通过Python的urllib库，爬取DLL共享网站https://cn.dll-files.com, 并下载dll文件。软件运行后，按照提示提示搜索下载就可以了，非常很简单。 方法3：在对应的目录检查一下文件命名的问题 &emsp;&emsp;这个问题一般不会出现，一般由于自己下载的dll文件已经放在对应目录下但是由于命名的原因没有识别到。 方法4：重新安装程序 &emsp;&emsp;重新执行出现问题程序的安装程序，重新安装来解决dll丢失问题。不过对于系统dll文件丢失和.exe程序没有作用。 方法5：使用Windows系统文件检查器修复.dll错误（sfc / scannow） https://www.reneelab.com.cn/windows-10-sfc-scannow.html 方法6：重启大法 &emsp;&emsp;在使用多种方法不起效或者使用重装大法之前，可以使用重启系统试试。重启可以让没启用的配置生效，或许可以解决你的问题。 方法7：通过重装或者更新Windows操作系统来摆脱dll错误 &emsp;&emsp;这个方法成本太大了，不建议使用 一般来说，大多数问题通过这些方法都是可以解决的。如果还有的话，请留言告诉我一声。哈哈","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Dll文件丢失","slug":"Dll文件丢失","permalink":"https://tomsworkspace.github.io/tags/Dll%E6%96%87%E4%BB%B6%E4%B8%A2%E5%A4%B1/"}]},{"title":"CPU Cache","slug":"CPU-Cache","date":"2019-11-17T12:20:30.000Z","updated":"2020-01-15T09:34:55.290Z","comments":true,"path":"2019/11/17/CPU-Cache/","link":"","permalink":"https://tomsworkspace.github.io/2019/11/17/CPU-Cache/","excerpt":"","text":"Linux的CPU cache一． CPU 与 Memory 内存之间的三级缓存的实现原理1.1 cache 存在的原理&emsp;&emsp;引入 Cache 的理论基础是程序局部性原理，包括时间局部性和空间局部性。时间局部性原理即最近被CPU访问的数据，短期内CPU 还要访问（时间）；空间局部性即被CPU访问的数据附近的数据，CPU短期内还要访问（空间）。因此如果将刚刚访问过的数据缓存在一个速度比主存快得多的存储中，那下次访问时，可以直接从这个存储中取，其速度可以得到数量级的提高。 &emsp;&emsp;CPU缓存是（Cache Memory）位于CPU与内存之间的临时存储器，它的容量比内存小但交换速度快。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可避开内存直接从缓存中调用，从而加快读取速度。 &emsp;&emsp;在CPU中加入缓存是一种高效的解决方案，是对于存储器件成本更低，速度更快这两个互相矛盾的目标的一个最优解决方案，这样整个内存储器（缓存+内存）就变成了既有缓存的高速度，又有内存的大容量的存储系统了。缓存对CPU的性能影响很大，主要是因为CPU的数据交换顺序和CPU与缓存间的带宽引起的。下图是一个典型的存储器层次结构，我们可以看到一共使用了三级缓存 各级存储访问延迟的对比 1.2 cpu 三级cache&emsp;&emsp;介于CPU和主存储器间的高速小容量存储器，由静态存储芯片SRAM组成，容量较小但比主存DRAM技术更加昂贵而快速， 接近于CPU的速度。CPU往往需要重复读取同样的数据块， Cache的引入与缓存容量的增大，可以大幅提升CPU内部读取数据的命中率，从而提高系统性能。通常由高速存储器、联想存储器、地址转换部件、替换部件等组成。如图所示。 联想存储器：根据内容进行寻址的存储器（冯氏模型中是按照地址进行寻址，但在高速存储器中往往只存有部分信息，此时需要根据内容进行检索） 地址转换部件：通过联想存储器建立目录表以实现快速地址转换。命中时直接访问Cache；未命中时从内存读取放入Cache 替换部件：在缓存已满时按一定策略进行数据块替换，并修改地址转换部件 &emsp;&emsp;早期采用外部（Off-chip）Cache，不做在CPU内而是独立设置一个Cache。现在采用片内（On-chip）Cache，将Cache和CPU作在一个芯片上，且采用多级Cache，同时使用L1 Cache和L2 Cache，甚至有L3 Cache。 一般L1 Cache都是分立Cache，分为数据缓存和指令缓存，可以减少访存冲突引起的结构冒险，这样多条指令可以并行执行；内置；其成本最高，对CPU的性能影响最大多级Cache的情况下，L1 Cache的命中时间比命中率更重要 一般L2 Cache都是联合Cache，这样空间利用率高没有L3 Cache的情况下，L2 Cache的命中率比命中时间更重要（缺失时需从主存取数，并要送L1和L2 cache） L3 Cache多为外置，在游戏和服务器领域有效；但对很多应用来说，总线改善比设置L3更加有利于提升系统性能 &emsp;&emsp;上图显示了最简单的缓存配置。它对应着最早期使用CPU cache的系统的架构。CPU内核不再直接连接到主内存。所有的数据加载和存储都必须经过缓存。CPU核心与缓存之间的连接是一种特殊的快速连接。在一个简化的表示中，主存和高速缓存连接到系统总线，该系统总线也可用于与系统的其他组件进行通信。我们引入了系统总线（现代叫做“FSB”）。引入缓存后不久，系统变得更加复杂。高速缓存和主存之间的速度差异再次增大，使得另一个级别的高速缓存不得不被添加进来，它比第一级高速缓存更大且更慢。出于经济原因，仅增加第一级缓存的大小不是一种选择。今天，甚至有机器在生产环境中使用了三级缓存。带有这种处理器的系统如图下所示。随着单个CPU的内核数量的增加，未来的缓存级别数量可能会增加。现在已经出现了拥有四级cache的处理器了。 &emsp;&emsp;上图展示了三级缓存的结构。L1d是一级数据cache，L1i是一级指令cache。请注意，这只是一个示意图; 现实中的数据流从core到主存的过程中不需要经过任何更高级别的cache。CPU设计人员有很大的自由来设计cache的接口。对于程序员来说，这些设计选择是不可见的。另外，我们有拥有多个core的处理器，每个core可以有多个“线程”。核心和线程之间的区别在于，独立的核心具有所有硬件资源的独立的副本，早期的多核处理器，甚至具有单独的第二级缓存而没有第三级缓存。核心可以完全独立运行，除非它们在同一时间使用相同的资源，例如与外部的连接。另一方面，线程们共享几乎所有的处理器资源。英特尔的线程实现只为线程提供单独的寄存器，甚至是有限的，还有一些寄存器是共享的。一个现代CPU的完整概貌如图所示。 i-cache和d-cache都是32KB、8路、4个时钟周期； L2 cache：256KB 、8路、11个时钟周期。 所有核共享的L3 cache：8MB、16路、30~40个时钟周期。 Core i7中所有cache的块大小都是64B 1.3 cpu cache与TLB的联系&emsp;&emsp;由于cache中对应的都是主存地址，即物理地址，在cqu查看具体数据是否在cache中时，如果CPU传送过来的地址时一个虚拟地址，需要将其转换成实际物理地址再到cache中去寻找。Cache的实现需要TLB的帮助。可以说TLB命中是Cache命中的基本条件。TLB不命中，会更新TLB项，这个代价非常大，Cache命中的好处基本都没有了。在TLB命中的情况下，物理地址才能够被选出，Cache的命中与否才能够达成。 1.3.1 TLB的概述&emsp;&emsp;TLB是一个内存管理单元用于改进虚拟地址到物理地址转换速度的缓存。TLB是位于内存中的页表的cache，如果没有TLB，则每次取数据都需要两次访问内存,即查页表获得物理地址和取数据。 1.3.2 TLB的原理&emsp;&emsp;当cpu对数据进行读请求时,CPU根据虚拟地址(前20位)到TLB中查找.TLB中保存着虚拟地址(前20位)和页框号的对映关系,如果匹配到虚拟地址就可以迅速找到页框号(页框号可以理解为页表项),通过页框号与虚拟地址后12位的偏移组合得到最终的物理地址. &emsp;&emsp;如果没在TLB中匹配到虚拟地址,就出现TLB丢失,需要到页表中查询页表项,如果不在页表中,说明要读取的内容不在内存,需要到磁盘读取. &emsp;&emsp;TLB是MMU中的一块高速缓存,也是一种Cache.在分页机制中,TLB中的数据和页表的数据关联,不是由处理器维护,而是由OS来维护,TLB的刷新是通过装入处理器中的CR3寄存器来完成.如果MMU发现在TLB中没有命中,它在常规的页表查找后,用找到的页表项替换TLB中的一个条目. 1.3.3 TLB的刷新原则&emsp;&emsp;当进程进行上下文切换时重新设置cr3寄存器,并且刷新tlb.有两种情况可以避免刷tlb. 第一种情况是使用相同页表的进程切换. 第二种情况是普通进程切换到内核线程.lazy-tlb(懒惰模式)的技术是为了避免进程切换导致tlb被刷新.当普通进程切换到内核线程时,系统进入lazy-tlb模式,切到普通进程时退出该模式. 1.3.4 cache的概念&emsp;&emsp;cache是为了解决处理器与慢速DRAM(慢速DRAM即内存)设备之间巨大的速度差异而出现的。cache属于硬件系统,linux不能管理cache.但会提供flush整个cache的接口.cache分为一级cache,二级cache,三级cache等等.一级cache与cpu处于同一个指令周期. 1.3.5 Cache的存取单位(Cache Line)&emsp;&emsp;CPU从来不从DRAM直接读/写字节或字,从CPU到DRAM的每次读或写的第一步都要经过L1 cache,每次以整数行读或写到DRAM中.Cache Line是cache与DRAM同步的最小单位.典型的虚拟内存页面大小为4KB,而典型的Cache line通常的大小为32或64字节. &emsp;&emsp;CPU 读/写内存都要通过Cache,如果数据不在Cache中,需要把数据以Cache Line为单位去填充到Cache,即使是读/写一个字节.CPU 不存在直接读/写内存的情况,每次读/写内存都要经过Cache. 1.3.6 Cache的工作模式 数据回写(write-back):这是最高性能的模式,也是最典型的,在回写模式下,cache内容更改不需要每次都写回内存,直到一个新的 cache要刷新或软件要求刷新时,才写回内存. 写通过(write-through):这种模式比回写模式效率低,因为它每次强制将内容写回内存,以额外地保存cache的结果,在这种模式写耗时,而读和回写模一样快,这都为了内存与cache相一致而付出的代价. 预取 (prefectching):一些cache允许处理器对cache line进行预取,以响应读请求,这样被读取的相邻内容也同时被读出来,如果读是随机的,将会使CPU变慢,预取一般与软件进行配合以达到最高性能. 二. 各级缓存中数据的包含关系2.1 整个缓存和主存间&emsp;&emsp;缓存里有的数据，主存中一定存在。 2.2 各级缓存之间&emsp;&emsp;一级缓存中还分数据缓存（data cache，d-cache）和指令缓存（instruction cache，i-cache）。二者分别用来存放数据和执行这些数据的指令，而且两者可以同时被cpu访问，所以一级cache间数据时独立的。 &emsp;&emsp;一级没有的数据二级可能有也可能没有。因为一级缓存miss会接着访问二级缓存。 &emsp;&emsp;一级有二级一定有，三级也一定有。因为一级的数据从二级中读上来的。在一级缺失二级命中时发生。 &emsp;&emsp;二级没有的数据三级可能有也可能没有。因为二级确实会接着访问三级缓存。找不到会继续访问主存。 &emsp;&emsp;二级有的数据三级一定有。在二级缺失三级命中时，数据会从三级缓存提到二级缓存。 &emsp;&emsp;三级没有的数据，主存可能有也可能没有。三级缓存缺失，会访问主存，主存也缺失就要从外存访问数据了。 &emsp;&emsp;三级缓存有的数据主存一定有。因为在三级缺失主存命中时，数据会从主存提到三级缓存中来。 三. 各级缓存的大小设置&emsp;&emsp;一级缓存就是指CPU第一层级的高速缓存，主要是为了缓存指令和缓存数据，一级缓存的容量对CPU性能影响非常大，但是因为成本太高，所以一般容量特别小，也就256KB左右。 &emsp;&emsp;二级缓存是CPU第二层级的高速缓存，对于CPU来说，二级缓存容量越大越好，它是直接影响CPU性能的，CPU每个核心都会有自己的缓存，一个CPU的二级缓存容量是所有核心二级缓存容量的总和。 &emsp;&emsp;三级缓存就是CPU第三层级的高速缓存，主要是为了降低与内存进行数据传输时的延迟问题，三级缓存与一二级不同，三级缓存只有一个，它是所有核心共享，所以在CPU参数中可以看到，三级缓存相对于其他两级缓存来说都很大。 &emsp;&emsp;由于缓存的设置与OS无关且透明，所以对于不同的体系架构下不同的处理器对待缓存区域的处理和方式都不同，不同的处理器也有不同的缓存设置值。从主流的处理器cache大小来看，一般一个cache line的大小都是固定的64B左右，这是经过经验得到的比较合理的大小，一般一级cache大小在数十KB左右，二级cache大小在数十到数百KB左右，而L3 cache大小在数MB左右。 四. 各级缓存之间的数据放置与数据淘汰策略&emsp;&emsp;由于三级cache一般来说是运用于拥有多核的处理器，对于单核处理器来说二级cache就能够足够保持够高的cache命中率。所以一般的三级cache一般只针对于多核处理器。L1和L2级cache是处理器核所单独的内容。L1又可以看成是L2的cache。L2可以看成是L3级cache的cache。所以我们分两个部分讨论数据放置与数据淘汰策略。 4.1 各级cache之间数据放置方式&emsp;&emsp;各级cache间的数据放置策略主要有三种。直接相连映射，全相联映射和组相联映射。将一个主存块存储到唯一的一个Cache行。对应的大小都是一个cache line的大小，一般来说是64B。 4.1.1直接相连映射&emsp;&emsp;多对一的映射关系，但一个主存块只能拷贝到cache的一个特定行位置上去。cache的行号i和主存的块号j有如下函数关系：i=j mod m（m为cache中的总行数）。 优点：硬件简单，容易实现 缺点：命中率低， Cache的存储空间利用率低 4.1.2全相联映射&emsp;&emsp;可以将一个主存块存储到任意一个Cache行。主存的一个块直接拷贝到cache中的任意一行上 优点：命中率较高，Cache的存储空间利用率高 缺点：线路复杂，成本高，速度低 4.1.3组相联映射&emsp;&emsp;可以将一个主存块存储到唯一的一个Cache组中任意一个行。将cache分成u组，每组v行，主存块存放到哪个组是固定的，至于存到该组哪一行是灵活的，即有如下函数关系：cache总行数m＝u×v 组号q＝j mod u &emsp;&emsp;组间采用直接映射，组内为全相联。硬件较简单，速度较快，命中率较高。是现代处理器中一般所常用的映射方式。 4.2 数据淘汰策略&emsp;&emsp;Cache工作原理要求它尽量保存最新数据，当从主存向Cache传送一个新块，而Cache中可用位置已被占满时，就会产生Cache替换的问题。常用的替换算法有下面三种。 4.2.1 LFU&emsp;&emsp;LFU（Least Frequently Used，最不经常使用）算法将一段时间内被访问次数最少的那个块替换出去。每块设置一个计数器，从0开始计数，每访问一次，被访块的计数器就增1。当需要替换时，将计数值最小的块换出，同时将所有块的计数器都清零。这种算法将计数周期限定在对这些特定块两次替换之间的间隔时间内，不能严格反映近期访问情况，新调入的块很容易被替换出去。 4.2.2 LRU&emsp;&emsp;LRU（Least Recently Used，近期最少使用）算法是把CPU近期最少使用的块替换出去。这种替换方法需要随时记录Cache中各块的使用情况，以便确定哪个块是近期最少使用的块。每块也设置一个计数器，Cache每命中一次，命中块计数器清零，其他各块计数器增1。当需要替换时，将计数值最大的块换出。&emsp;&emsp;LRU算法相对合理，但实现起来比较复杂，系统开销较大。这种算法保护了刚调入Cache的新数据块，具有较高的命中率。LRU算法不能肯定调出去的块近期不会再被使用，所以这种替换算法不能算作最合理、最优秀的算法。但是研究表明，采用这种算法可使Cache的命中率达到90%左右。 4.2.3 随机替换&emsp;&emsp;最简单的替换算法是随机替换。随机替换算法完全不管Cache的情况，简单地根据一个随机数选择一块替换出去。随机替换算法在硬件上容易实现，且速度也比前两种算法快。缺点则是降低了命中率和Cache工作效率。 五. 整个缓存结构的访问流程5.1 查找命中&emsp;&emsp;处理器微架构访问Cache的方法与访问主存储器有类似之处。主存储器使用地址编码方式，微架构可以地址寻址方式访问这些存储器。Cache也使用了类似的地址编码方式，微架构也是使用这些地址操纵着各级Cache，可以将数据写入Cache，也可以从Cache中读出内容。只是这一切微架构针对Cache的操作并不是简单的地址访问操作。为简化起见，我们忽略各类Virtual Cache，讨论最基础的Cache访问操作，并借此讨论CPU如何使用TLB完成虚实地址转换，最终完成对Cache的读写操作。 &emsp;&emsp;Cache的存在使得CPU Core的存储器读写操作略微显得复杂。CPU Core在进行存储器方式时，首先使用EPN(Effective Page Number)进行虚实地址转换，并同时使用CLN(Cache Line Number)查找合适的Cache Block。这两个步骤可以同时进行。在使用Virtual Cache时，还可以使用虚拟地址对Cache进行寻址。为简化起见，我们并不考虑Virtual Cache的实现细节。 &emsp;&emsp;EPN经过转换后得到VPN，之后在TLB中查找并得到最终的RPN(Real Page Number)。如果期间发生了TLB Miss，将带来一系列的严重的系统惩罚，我们只讨论TLB Hit的情况，此时将很快获得合适的RPN，并依此得到PA(Physical Address)。 &emsp;&emsp;在多数处理器微架构中，Cache由多行多列组成，使用CLN进行索引最终可以得到一个完整的Cache Block。但是在这个Cache Block中的数据并不一定是CPU Core所需要的。因此有必要进行一些检查，将Cache Block中存放的Address与通过虚实地址转换得到的PA进行地址比较(Compare Address)。如果结果相同而且状态位匹配，则表明Cache Hit。此时微架构再经过Byte Select and Align部件最终获得所需要的数据。如果发生Cache Miss，CPU需要使用PA进一步索引主存储器获得最终的数据。 &emsp;&emsp;由上文的分析，我们可以发现，一个Cache Block由预先存放的地址信息，状态位和数据单元组成。一个Cache由多个这样的Cache Block组成，在不同的微架构中，可以使用不同的Cache Block组成结构。我们首先分析单个Cache Block的组成结构。单个Cache Block由Tag字段，状态位和数据单元组成，如图所示。 &emsp;&emsp;其中Data字段存放该Cache Block中的数据，在多数处理器微架构中，其大小为32或者64字节。Status字段存放当前Cache Block的状态，在多数处理器系统中，这个状态字段包含MESI，MOESI或者MESIF这些状态信息，在有些微架构的Cache Block中，还存在一个L位，表示当前Cache Block是否可以锁定。许多将Cache模拟成SRAM的微架构就是利用了这个L位。有关MOESIFL这些状态位的说明将在下文中详细描述。在多核处理器和复杂的Cache Hierarchy环境下，状态信息远不止MOESIF。 &emsp;&emsp;RAT(Real Address Tag)记录在该Cache Block中存放的Data字段与那个地址相关，在RAT中存放的是部分物理地址信息，虽然在一个CPU中物理地址可能有40，46或者48位，但是在Cache中并不需要存放全部地址信息。因为从Cache的角度上看，CPU使用的地址被分解成为了若干段，如图所示。 &emsp;&emsp;这个地址也可以理解为CPU访问Cache使用的地址，由多个数据段组成。首先需要说明的是Cache Line Index字段。这一字段与Cache Line Number类似，CPU使用该字段从Cache中选择一个或者一组Entry。 &emsp;&emsp;Bank和Byte字段之和确定了单个Cache的Data字段长度，通常也将这个长度称为Cache 行长度，上图所示的微架构中的Cache Block长度为64字节。目前多数支持DDR3 SDRAM的微架构使用的Cache Block长度都是64字节。部分原因是由于DDR3 SDRAM的一次Burst Line为8，一次基本Burst操作访问的数据大小为64字节。 &emsp;&emsp;在处理器微架构中，将地址为Bank和Byte两个字段出于提高Cache Block访问效率的考虑。Multi-Bank Mechanism是一种常用的提高访问效率的方法，采用这种机制后，CPU访问Cache时，只要不是对同一个Bank进行访问，即可并发执行。Byte字段决定了Cache的端口位宽，在现代微架构中，访问Cache的总线位宽为64位或者为128位。 &emsp;&emsp;剩余的字段即为Real Address Tag，这个字段与单个Cache中的Real Address Tag的字段长度相同。CPU使用地址中的Real Address Tag字段与Cache Block的对应字段和一些状态位进行联合比较，判断其访问数据是否在Cache中命中 5.2 cache 不命中&emsp;&emsp;如果cache miss,就去下一级cache或者主存中去查找数据，并将查找到的数据采用上面的数据淘汰策略将数据替换到cache中。 5.3 cache和主存数据一致性保持&emsp;&emsp;由于在发生cache miss时会产生数据替换，在运行过程中缓存的数据也可能会被修改。所以需要一个策略来保持数据在缓存和主存间的一致性。Cache写机制分为write through和write back两种。 Write-through（直写模式）在数据更新时，同时写入缓存Cache和主存存储。此模式的优点是操作简单；缺点是因为数据修改需要同时写入存储，数据写入速度较慢。 Write-back（回写模式）在数据更新时只写入缓存Cache。只在数据被替换出缓存时，被修改的缓存数据才会被写到后端存储。此模式的优点是数据写入速度快，因为不需要写存储；缺点是一旦更新后的数据未被写入存储时出现系统掉电的情况，数据将无法找回。","categories":[{"name":"Linux kernel","slug":"Linux-kernel","permalink":"https://tomsworkspace.github.io/categories/Linux-kernel/"}],"tags":[{"name":"cache","slug":"cache","permalink":"https://tomsworkspace.github.io/tags/cache/"},{"name":"CPU cache","slug":"CPU-cache","permalink":"https://tomsworkspace.github.io/tags/CPU-cache/"},{"name":"三级缓存","slug":"三级缓存","permalink":"https://tomsworkspace.github.io/tags/%E4%B8%89%E7%BA%A7%E7%BC%93%E5%AD%98/"},{"name":"缓存映射","slug":"缓存映射","permalink":"https://tomsworkspace.github.io/tags/%E7%BC%93%E5%AD%98%E6%98%A0%E5%B0%84/"},{"name":"cache原理","slug":"cache原理","permalink":"https://tomsworkspace.github.io/tags/cache%E5%8E%9F%E7%90%86/"},{"name":"多级cache","slug":"多级cache","permalink":"https://tomsworkspace.github.io/tags/%E5%A4%9A%E7%BA%A7cache/"},{"name":"TLB","slug":"TLB","permalink":"https://tomsworkspace.github.io/tags/TLB/"}]},{"title":"搭建个人博客","slug":"搭建个人博客","date":"2019-11-13T08:36:37.000Z","updated":"2020-01-15T12:47:24.536Z","comments":true,"path":"2019/11/13/搭建个人博客/","link":"","permalink":"https://tomsworkspace.github.io/2019/11/13/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"对于常年需要学习新东西的人们，经常想把学过的一些东西整理一下。于是写博客就成了很多人整理自己学习过的东西的很好的方式。有人选择在一些成熟的平台上管理自己的博客，比如知乎，CSDN，简书这些平台。不过在别人的平台上写东西很容易受到各种限制，内容也有各种各样的要求。哪有比自己搭一个私人博客网站更炫酷（装*）的呢！！！！ 哈哈，let’s go.","text":"对于常年需要学习新东西的人们，经常想把学过的一些东西整理一下。于是写博客就成了很多人整理自己学习过的东西的很好的方式。有人选择在一些成熟的平台上管理自己的博客，比如知乎，CSDN，简书这些平台。不过在别人的平台上写东西很容易受到各种限制，内容也有各种各样的要求。哪有比自己搭一个私人博客网站更炫酷（装*）的呢！！！！ 哈哈，let’s go. 一.效果展示经过特别简单的配置（大概几个小时），一个属于个人的博客网站就搭好了，可以开始更新自己的内容了，毕竟内容才是最重要的啊。 效果如下： 二.前期准备经过总结前人的经验，我把搭建一个个人的博客分为大概三种可行的方案： 第一种方案：搭建一个通过Github pages访问的博客网站。但是这样的话只能通过访问 http://github用户名.github.io的方式访问自己的博客网站，毕竟不够炫酷，但是是免费的。于是有了第二种方案。 第二种方案：把 http://github用户名.github.io绑定到自己的域名，购买一个域名需要一定的费用。 第三种方案：把博客系统放到自己购买服务器上，这样能通过服务器的IP地址访问博客网站，绑定域名后可以通过域名来访问。这是最炫酷的方式，当然也是pay最多的，而且网站还需要经过备案。 由于自己热爱open sourse（其实是没钱），于是我选择了第一种的方案。希望后面有钱了可以实现第三种方案。哈哈。 2.1 选择一个博客框架为了避免重复造轮子，也为了简单和高效起见，我们需要选择一个已有的博客框架，再在这些框架的基础上搭建。有很多还不错的开源博客框架可以选择。简单列举几个： - Jekyll - hugo - django - hexo 经过比较，发现hexo框架还不错，有比较好的扩展性和很大的用户基础。于是Tom就选了hexo作为博客的框架。想选择其他框架的请参照具体官网文档,和他们的GitHub issues。 2.2 hexo框架的简介Hexo 特点 支持Markdown: 支持Markdown意味着你可以把经历从排版中解放出来 轻量: 无需拥有后台及数据库,专心写好你的文章 一键部署: 可以通过Git或者ftp来将生成的静态页面部署到服务器或者主机空间中 插件丰富: 丰富的插件可以满足你的各种需求 其他特性，请参考官方文档. 2.3 配置必要的环境搭建前期需要四个工具 Hexo:Hexo快速、简洁且高效的博客框架 Node.js:建立在Chrome上的JavaScript运行引擎 Git:一款免费、开源的分布式版本控制系统 GitHub:国内一款面向开发者的云端开发平台，提供代码托管，运行空间，质量控制，项目管理等功能安装 安装必要的配置环境，如果已经安装过，可以跳过。 2.3.1 安装Git Git官网找到Download,安装自己对应的系统版本，系统会自动判定你当前版本，推荐下载，如果没有推荐，那就自己选择吧。 安装完后，用win+R打开cmd界面，输入 $git --version 出现git的版本信息说明安装成功。 然后熟悉一下Git管理Github项目的常用命令，理解一下他们的关系,感受一下git版本和分支管理的强大之处。 2.3.2 安装Node.js Node.js下载地址安装node.js记得选择add to path选项，或者手动配置环境变量。把node所在的bin目录加入环境变量。用win+R打开cmd界面，输入 $node 出现node.js的版本信息说明安装成功。 同理系统依然会判定你的系统并给出稳定推荐的版本和尝鲜版，两种，供君选择。下载安装步骤同样省略。 2.3.3 GitHub账号注册GitHub账号注册过程很简单，注册流程就省略，完成之后，就开始创建博客了。注册完成后，创建名字为 username.github.io 的仓库,username是你的github用户名。记住一定是这个名字的仓库，不然会出问题的。 2.3.4 安装Hexo前面的所有工具安装完成后，在git bash或者cmd界面中使用npm安装hexo。 $npm install -g hexo-cli 进阶安装和使用,对于熟悉 npm 的进阶用户，可以仅局部安装 hexo 包。 $npm install hexo 安装 Hexo 完成后，请执行下列命令查看安装hexo的版本信息。 $hexo version 然后运行以下命令，Hexo 将会在指定文件夹中新建所需要的文件。这个指定的文件夹就是保存你的博客站点所有文件的地方。 $hexo init &lt;folder&gt;$cd &lt;folder&gt; $npm install 站点文件包含以下的文件 . ├── _config.yml //网站的配置文件 ├── package.json //应用程序的信息 ├── scaffolds //模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。 ├── source //资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。 | ├── _drafts | └── _posts └── themes //主题 文件夹。Hexo 会根据主题来生成静态页面。更多关于站点目录和配置文件的信息。 安装git,hexo，node.js后，熟悉相关命令。不同系统环境下安装遇到的问题请参考官方文档,官方文档支持中英文，很方便。 三.hexo框架搭建博客3.1 建立hexo项目，本地localhost:port访问在上一步生成了站点文件夹后，其中会有一个默认主题以及一个hello-word的默认文章。所以我们可以先生成博客来看一下效果，在站点所在目录打开git bash运行命令： $hexo generate //可以简写成$hexo g 然后hexo会开始生成博客，生成结束后，文件夹下会多出一个public的文件夹，这个文件夹就是hexo生成的一个完整的静态网站，也就是我们的博客。网站生成好了，我们要浏览它，所以要开启一下hexo自带的服务器，运行命令： $hexo server //可以简写成$hexo s 这时候，打开浏览器，输入localhost：4000即可访问博客网站。如果出现端口冲突，可以使用如下的命令指定其他端口。再使用localhost：port去访问。 $hexo server -p port //可以简写成$hexo g -p port 3.2 远程部署，绑定SSH,域名访问远程部署指的是，博客在我们本地生成好了以后部署到远程仓库去，如果远程仓库支持pages服务的话，那就可以通过这样的方法发布和更新博客。要使用远程部署需要先安装hexo-deployer-git，注意，这是适用于git类型仓库的方法，其他仓库的方法在官网中有说明。 运行命令 $npm install hexo-deployer-git --save //安装hexo-deployer-git package 安装好hexo-deployer-git后，修改博客目录配置文件_config.yml中的deploy字段，用记事本打开就可以： deploy: type: git //pages 部署仓库类型 repo: //git仓库项目地址，你建立的 用户名.github.io仓库 branch: //分支，默认是master message: //自定义提交说明，这个字段可以没有，用于描述你的提交再运行 $hexo deploy 打开github的repo,发现你的仓库里已经有了文件，这是生成的博客网站的静态文件。也就是本地博客文件夹中的public 或者.deploy_git中的内容。hexo生成了你的博客网站的静态文件。在浏览器地址栏输入http://username.github.io就可以访问你的个人博客网站了。很炫酷吧。 参考的一些资料 https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.htmlhttps://blog.csdn.net/gsl9d1p04f6x2ts3c9/article/details/81024330https://blog.csdn.net/dazhaoDai/article/details/73730069https://www.jianshu.com/p/343934573342 绑定SSH Git使用https协议，每次pull, push都要输入密码，相当的烦。使用git协议，然后使用ssh密钥。这样可以省去每次都输密码。为了方便你的博客的提交，你可以进行git与repo仓库的SSH绑定。 SSH绑定git仓库的特点： ssh方式单独使用非对称的秘钥进行认证和加密传输，和账号密码分离开来，不需要账号也可以访问repo。 生成和管理秘钥有点繁琐，需要管理员添加成员的public key。不能进行匿名访问，ssh不利于对权限进行细分，用户必须具有通过SSH协议访问你主机的权限，才能进行下一步操作，比较适合内部项目。 如何进行SSH配置。 四.更换主题4.1 给你的博客选择一个主题经过以上的配置，你的博客网站已经跑起来了。不过是不是有点丑呢？看来需要进一步的美化我们的网站啊。当然Hexo,也大力支持我们的想法，Hexo提供了很多漂亮的主题供我们选择。Hexo主题。是不是发现有很多主题让你眼花缭乱了，如果不知道应该选哪一个，可以听一听来自前人的建议主题推荐1 主题推荐2。 4.2 更改相关配置找到自己喜欢的主题，把对应的主题下载到本地站点文件夹下的themes文件夹下。Tom选择了一个名为Butterfly的主题。想要让这个主题应用到我自己的站点上。需要进行如下的操作。 下载主题 找到下载主题的Github repo地址，在站点文件夹下右键打开git bash,输入命令 $git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git themes/Butterfly 如果想要安装比较新的dev分支，可以 $git clone -b dev https://github.com/jerryc127/hexo-theme-butterfly.git themes/Butterfly 应用主题 修改hexo配置文件_config.yml，把主题改为Butterfly theme: Butterfly对于不同的主题，可能还有其他的配置才能生效，参加你选择主题的相关文档说明，关于主题Butterfly配置。 如果你没有pug以及stylus的渲染器，请下载安装： $npm install hexo-renderer-pug hexo-renderer-stylus --save 或者 $yarn add hexo-renderer-pug hexo-renderer-stylus 然后再次generate ,depoly，访问地址，主题就更换好了。 疑难问题解决 五.项目管理5.1 写博客，删除博客首先，由于hexo是支持Markdown来编写你的博客的，非常方便。markdown语法也是非常简单的，类似于html,很快就能掌握。在开始写你的博客之前需要先掌握一下。 但是在实际使用时发现了一个问题。在不同的平台对于markdown语法的支持不太一样，但是大多是东西是一样的，对于博客在不同平台间的迁移不太方便。暂时没有太好的解决办法，等有比较好的解决方法时更新一下。hexo支持的markdown 语法和github的markdown语法是一样的。然后最好是选择一个对于hexo markdown语法支持得比较好的makedown编辑器。 其他的markdown语法资料 https://segmentfault.com/markdown https://www.jianshu.com/p/8c1b2b39deb0 5.2 上传更新博客先在本地预览一下写好的博客，在站点文件夹下使用git bash运行 $hexo generate //hexo g$hexo server //hexo s 检查没问题后，提交更新 $hexo deploy //hexo d 六.高级功能6.1 评论管理如何给我们的评论添加评论功能呢？ 以Tom选择的Butterfly主题为例，打开主题的配置文件夹_config.yml,注意不是站点的配置文件。搜索Comments,发现该主题支持如下的几种评论系统 disqus laibili gitalk valine 可以任选一种评论系统进行配置。大致流程为先注册对应的评论系统，再进行一些配置。主题Butterfly相关配置参见主题butterfly相关文档。 其他的配置方法。 6.2 绑定域名是不是感觉使用githubusername.github.io访问自己的博客还是不够炫酷呢？于是可以给自己的网站绑定一个炫酷的域名，也就是相当于给你的网站起了一个别名，本质上都是通过DNS查找ip地址，然后通过IP地址访问的你的网站的。 可以在CMD界面下通过命令来查看你博客的ip地址。 $ping username.github.io //ping 你的博客网址 首先注册一个域名，在阿里云上注册或者买一个域名。打开控制台，点击解析域名，把你刚刚查到的ip地址填到刚刚解析的域名的记录值上面。然后在你的博客文件夹下面新建一个名为CNAME的文件，在里面写入你刚刚购买的域名。然后提交你的站点静态文件到仓库里。等待一段时间，然后就可以通过刚刚购买的域名访问你的网站了。 6.3 部署站点到自己的服务器如果你觉得上面的配置还不过炫酷，速度不够快，毕竟github是国外的网站，那么还有更厉害的，把网站放到自己的服务器上。 网站备案 首先，需要进行网站备案。根据工信部《互联网信息服务管理办法》(国务院 292 号令)，网站在未完成备案之前，不能指向大陆境内服务器开通访问。如果您的网站托管在中国大陆节点服务器，或者开通 CDN 服务，就必须申请 ICP(互联网内容提供商)备案。若网站服务器为非中国大陆节点，则不用申请备案。 然后购买一个服务器，把你的域名绑定到你的服务器上。 在你的服务器上安装Git并配置,安装并搭建web容器，如nginx,Tomcat等。 然后服务器获取站点静态文件有两种方式： 通过把站点静态文件直接提交到服务器上的git仓库 通过从github上的username.github.io获取站点静态文件 这样就完成了最后的配置。 6.4 更换电脑或重装系统后恢复hexo当我们的系统崩溃或者是其他原因导致hexo不能用了，试试这个恢复。 6.5 配置一键部署：每次更新博客都需要进到博客站点下进行操作，还有一堆的命令要输入。配置一键部署。 6.6 自定义什么？ 你觉得所有的主题都不符合你的要求。没问题，hexo也支持你自己DIY主题，还可以发布给大家一起用。还支持自定义博客模板等功能。 6.7 博客迁移你想把自己博客发布到不同的平台上，或者是从其他平台上添加自己的博客。没问题，hexo也支持。试试博客迁移。 6.8 搜索引擎收录博客当我们一开始建完博客时，搜索引擎是搜索不到的，我们需要做一项工作就是通知搜索引擎收录我们的网站。 具体方法 6.9 jsDelivr免费CDN加速博客由于github的服务器是国外的服务器，访问速度相对较慢，特别是你的博客中使用了太多的图片等比较大的资源，这时候可以使用CDN加速给网站很快的访问速度。 具体方法 七.出现的一些问题git ssh配置Host key verification failed.YAMLException: can not read a block mapping entry; a multiline key may not be an implicit key at line 5, column bad indentation of a mapping entry at line 199, column 2:hexo YAMLException: cannot read a block mapping entry; a multi line key may not be an implicit key agitalk 出现not found 等问题深坑，申请gitalk账号一般不会出问题，一般问题出在配置_config.yml上。注意repo是只写仓库名字，不是全部路径啊。如username.github.io这样。 butterfly主题问题解答更多问题解答","categories":[{"name":"其他","slug":"其他","permalink":"https://tomsworkspace.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"TOM","slug":"TOM","permalink":"https://tomsworkspace.github.io/tags/TOM/"},{"name":"个人博客","slug":"个人博客","permalink":"https://tomsworkspace.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"personal blog","slug":"personal-blog","permalink":"https://tomsworkspace.github.io/tags/personal-blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://tomsworkspace.github.io/tags/Hexo/"},{"name":"Github pages","slug":"Github-pages","permalink":"https://tomsworkspace.github.io/tags/Github-pages/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-11-07T15:02:58.834Z","updated":"2019-11-14T14:49:59.053Z","comments":true,"path":"2019/11/07/hello-world/","link":"","permalink":"https://tomsworkspace.github.io/2019/11/07/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}